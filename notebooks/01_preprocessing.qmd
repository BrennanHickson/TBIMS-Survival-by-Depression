---
title: "Preprocessing"
author: "Brennan Hickson"
format: html
editor: visual
---

# Install and Load Libraries

```{r Initial Setup and Library Loading, echo = TRUE}
# Load the pacman package (install if necessary)
if (!requireNamespace("pacman", quietly = TRUE)) {
  install.packages("pacman")
}

# Install and load prerequisite libraries
pacman::p_load(haven, here, lubridate, sjlabelled, labelled, survival, tidyverse)

# Create the 'logs' subdirectory if not already accessible
log_dir <- here("logs")
if (!dir.exists(log_dir)) {
  dir.create(log_dir)
}

# Create the 'data/raw' subdirectory if not already accessible
data_raw_dir <- here("data", "raw")
if (!dir.exists(data_raw_dir)) {
  dir.create(data_raw_dir, recursive = TRUE)
}

# Create the 'data/processed' subdirectory if not already accessible
data_processed_dir <- here("data", "processed")
if (!dir.exists(data_processed_dir)) {
  dir.create(data_processed_dir, recursive = TRUE)
}

# Define the study period start and end dates
study_entry_period_start_date <- as.Date("2006-10-01")
study_entry_period_end_date <- as.Date("2012-10-01")

# Set a random seed for reproducibility
set.seed(42)
```

```{r Define a Function to Import the Data}
#' Import data from a file
#'
#' This function imports data from a file in either .sav or .csv format.
#'
#' @param file_path A character string specifying the path to the file to be imported.
#' @param file_type A character string specifying the file type. Must be either 'sav' or 'csv'.
#' @return A data frame containing the imported data.
#' @export
#' @examples
#' import_data("data.csv", "csv")

import_data <- function(file_path, file_type = c("sav", "csv")) {
  tryCatch({
    if (file_type == "sav") {
      read_sav(file_path)
    } else if (file_type == "csv") {
      read.csv(file_path)
    } else {
      stop("Unsupported file type. Please specify 'sav' or 'csv'.")
    }
  }, error = function(e) {
    cat("Error importing file:", file_path, "\nError message:", e$message, "\n")
    return(NULL)
  })
}
```

```{r Import Data}
# Specify the file paths to the datasets
tbims_form1_path <- here(data_raw_dir, "TBIMS_2023Q2_SPSS/TBIMSForm1_20230712.sav")
tbims_form2_path <- here(data_raw_dir, "TBIMS_2023Q2_SPSS/TBIMSForm2_20230726.sav")
function_scores_path <- here(data_raw_dir, "function_factorscore20240131.csv")

# Import TBIMS Form 1 and Form 2 data
tbims_form1_data <- import_data(tbims_form1_path, file_type = "sav")
tbims_form2_data <- import_data(tbims_form2_path, file_type = "sav")

# Save original TBIMS Form 1 and Form 2 variable labels before proceeding
tbims_form1_labels <- tbims_form1_data |> var_label()
tbims_form2_labels <- tbims_form2_data |> var_label()

# Import function factor scores
function_factor_scores <- import_data(function_scores_path, file_type = "csv")
```

## Define Data Cleaning Functions

```{r Define Data Cleaning Functions}
#' Handle Date conversions and NA replacement
#'
#' This function handles Date conversions and replaces specified na_codes (in Date format) with NA.
#'
#' @param x A vector.
#' @param na_codes A vector of codes that represent missing values.
#' @return A vector with missing values replaced by NA.
#' @export
handle_date_conversion <- function(x, na_codes) {
  # Convert to Date if x is not already a Date
  if (!inherits(x, "Date")) {
    x <- as.Date(x)
  }

  # Replace specified na_codes (in Date format) with NA
  na_codes <- lapply(na_codes, function(code) as.Date(code, format = "%Y-%m-%d"))
  for (code in na_codes) {
    x[x == code] <- NA
  }

  return(x)
}

#' Replace missing values and convert data types
#'
#' This function replaces specified missing value codes with NA and converts data types.
#'
#' @param x A vector.
#' @param na_codes A vector of codes that represent missing values.
#' @param to_class The class to which the vector should be converted.
#' @return A vector with missing values replaced by NA.
#' @export
#' @examples
#' replace_na(c(1, 2, 3, 4, 5), c(3, 4), "factor")
replace_na <- function(x, na_codes, to_class = NULL) {
  if (!is.null(to_class)) {
    if (to_class == "factor") {
      x <- as.character(x) # Convert to character first to handle haven_labelled cases
      x[x %in% na_codes] <- NA
      x <- factor(x, exclude = NA)
    } else if (to_class == "numeric") {
      x <- as.numeric(x)
      x[x %in% na_codes] <- NA
    } else if (to_class == "Date") {
      x <- handle_date_conversion(x, na_codes)
    } else if (to_class == "character") {
      x <- as.character(x)
      x[x %in% na_codes] <- NA
    }
  } else {
    # Default handling if to_class is not specified
    x[x %in% na_codes] <- NA
  }
  return(x)
}

#' Clean and convert data based on mapping rules
#'
#' This function cleans and converts data based on the rules outlined in a mapping list.
#'
#' @param data A data frame.
#' @param mapping_list A list of mapping rules.
#' @return A cleaned and converted data frame.
#' @export
#' @examples
#' clean_and_convert(mtcars, list(cyl = list(na_values = c(4, 6), original_name = "cyl", to_class = "factor")))
clean_and_convert <- function(data, mapping_list) {
  for (var in names(mapping_list)) {
    na_values <- mapping_list[[var]]$na_values
    original_name <- mapping_list[[var]]$original_name
    to_class <- mapping_list[[var]]$to_class

    # Renaming the variable
    data <- data |> 
      rename(!!var := all_of(original_name))

    # Replace specified values with NA based on their intended class
    data <- data |> mutate(!!var := replace_na(!!sym(var), na_values, to_class))

    # Handle haven_labelled data if present
    data <- data |> mutate(!!var := haven::zap_labels(!!sym(var)))
  }
  return(data)
}
```

```{r Define the Data Mappings for Data Cleaning}
# Variable name and NA mappings for baseline data
baseline_name_and_na_mappings <- list(
  id = list(original_name = "Mod1id", to_class = "numeric"),
  sex = list(original_name = "SexF", na_values = 99, to_class = "factor"),
  age_at_injury = list(original_name = "AGE", na_values = 9999, to_class = "numeric"),
  date_of_birth = list(original_name = "Birth", na_values = as.Date("9999-09-09"), to_class = "Date"),
  date_of_injury = list(original_name = "Injury", na_values = as.Date("9999-09-09"), to_class = "Date"),
  date_of_death = list(original_name = "Death", na_values = as.Date(c("8888-08-08", "9999-09-09")), to_class = "Date"),
  cause_of_injury = list(original_name = "Cause", na_values = 999, to_class = "factor"),
  marital_status_at_injury = list(original_name = "Mar", na_values = 99, to_class = "factor"),
  education_level_at_injury = list(original_name = "EduYears", na_values = c(21, 666, 999), to_class = "numeric"),
  employment_at_injury = list(original_name = "EMPLOYMENT", na_values = c(888, 999), to_class = "factor"),
  rehab_payor_primary = list(original_name = "RehabPay1", na_values = c(888, 999), to_class = "factor"),
  problematic_substance_use_at_injury = list(original_name = "PROBLEMUse", na_values = c(77, 99), to_class = "factor"),
  mental_health_tx_lifetime_at_injury = list(original_name = "MntlEver", na_values = c(66, 77, 99), to_class = "factor"),
  mental_health_tx_past_year_at_injury = list(original_name = "MntlPrior", na_values = c(66, 77, 99), to_class = "factor"),
  psych_hosp_hx_lifetime_at_injury = list(original_name = "PsyHosp", na_values = c(66, 77, 99), to_class = "factor"),
  psych_hosp_hx_past_year_at_injury = list(original_name = "PsyHospPrior", na_values = c(66, 77, 99), to_class = "factor"),
  suicide_attempt_hx_lifetime_at_injury = list(original_name = "Suicide", na_values = c(66, 77, 99), to_class = "factor"),
  suicide_attempt_hx_past_year_at_injury = list(original_name = "SuicidePrior", na_values = c(66, 77, 99), to_class = "factor"),
  cause_of_death_1 = list(original_name = "DeathCause1", na_values = c(44444, 88888, 99999, "09/09/9999"), to_class = "character"),
  cause_of_death_2 = list(original_name = "DeathCause2", na_values = c(44444, 88888, 99999, "09/09/9999"), to_class = "character"),
  cause_of_death_e = list(original_name = "DeathECode", na_values = c(44444, 88888, 99999, "09/09/9999"), to_class = "character")
  # problematic_substance_use_at_injury = list(original_name = "PROBLEMUse", na_values = 99, to_class = "factor"),
  # mental_health_tx_lifetime_at_injury = list(original_name = "MntlEver", na_values = c(66, 99), to_class = "factor"),
  # mental_health_tx_past_year_at_injury = list(original_name = "MntlPrior", na_values = c(66, 99), to_class = "factor"),
  # psych_hosp_hx_lifetime_at_injury = list(original_name = "PsyHosp", na_values = c(66, 99), to_class = "factor"),
  # psych_hosp_hx_past_year_at_injury = list(original_name = "PsyHospPrior", na_values = c(66, 99), to_class = "factor"),
  # suicide_attempt_hx_lifetime_at_injury = list(original_name = "Suicide", na_values = c(66, 99), to_class = "factor"),
  # suicide_attempt_hx_past_year_at_injury = list(original_name = "SuicidePrior", na_values = c(66, 99), to_class = "factor")
  )

# Variable name and NA mappings for follow-up data
followup_name_and_na_mappings <- list(
  id = list(original_name = "Mod1id", to_class = "numeric"),
  data_collection_period = list(original_name = "FollowUpPeriod", to_class = "numeric"),
  status_at_followup = list(original_name = "IntStatus", to_class = "factor"),
  date_of_followup = list(original_name = "Followup", na_values = as.Date(c("4444-04-04", "5555-05-05", "7777-07-07", "8888-08-08", "9999-09-09")), to_class = "Date"),
  date_of_death = list(original_name = "DeathF", na_values = as.Date(c("4444-04-04", "8888-08-08", "9999-09-09")), to_class = "Date"),
  drs_total_at_followup = list(original_name = "DRSF", na_values = 999, to_class = "numeric"),
  fim_total_at_followup = list(original_name = "FIMTOTF", na_values = 9999, to_class = "numeric"),
  gose_total_at_followup = list(original_name = "GOSEF", na_values = c(66, 99), to_class = "numeric"),
  problematic_substance_use_at_followup = list(original_name = "PROBLEMUseF", na_values = c(77, 99), to_class = "factor"),
  # psych_hosp_hx_past_year_at_followup = list(original_name = "PsyHospF", na_values = c(0, 6, 7, 9), to_class = "factor"),
  suicide_attempt_hx_past_year_at_followup = list(original_name = "SuicideF", na_values = c(66, 77, 88, 99), to_class = "factor"),
  # problematic_substance_use_at_followup = list(original_name = "PROBLEMUseF", na_values = 99, to_class = "factor"),
  # psych_hosp_hx_past_year_at_followup = list(original_name = "PsyHospF", na_values = c(0, 6, 9), to_class = "factor"),
  # suicide_attempt_hx_past_year_at_followup = list(original_name = "SuicideF", na_values = c(66, 88, 99), to_class = "factor"),
  phq1 = list(original_name = "PHQPleasureF", na_values = c(66, 81, 82, 99), to_class = "numeric"),
  phq2 = list(original_name = "PHQDownF", na_values = c(66, 81, 82, 99), to_class = "numeric"),
  phq3 = list(original_name = "PHQSleepF", na_values = c(66, 81, 82, 99), to_class = "numeric"),
  phq4 = list(original_name = "PHQTiredF", na_values = c(66, 81, 82, 99), to_class = "numeric"),
  phq5 = list(original_name = "PHQEAtF", na_values = c(66, 81, 82, 99), to_class = "numeric"),
  phq6 = list(original_name = "PHQBadF", na_values = c(66, 81, 82, 99), to_class = "numeric"),
  phq7 = list(original_name = "PHQConcentrateF", na_values = c(66, 81, 82, 99), to_class = "numeric"),
  phq8 = list(original_name = "PHQSlowF", na_values = c(66, 81, 82, 99), to_class = "numeric"),
  phq9 = list(original_name = "PHQDeadF", na_values = c(66, 81, 82, 99), to_class = "numeric"),
  cause_of_death_1 = list(original_name = "DeathCause1F", na_values = c(44444, 88888, 99999), to_class = "character"),
  cause_of_death_2 = list(original_name = "DeathCause2F", na_values = c(44444, 88888, 99999), to_class = "character"),
  cause_of_death_e = list(original_name = "DeathECodeF", na_values = c(44444, 88888, 99999), to_class = "character")
  )
```

```{r Clean Baseline and Follow-up Data}
# Add data collection period to baseline data
tbims_form1_data <- tbims_form1_data |>
  mutate(data_collection_period = 0)

# Clean and convert the Form 1 (baseline) and Form 2 (follow-up) data
clean_tbims_form1_data <- clean_and_convert(tbims_form1_data, baseline_name_and_na_mappings)
clean_tbims_form2_data <- clean_and_convert(tbims_form2_data, followup_name_and_na_mappings)
```

```{r Merge Baseline and Follow-up Data and Coalesce Shared Variables}
# Merge cleaned data
merged_data <- full_join(clean_tbims_form1_data, clean_tbims_form2_data, by = c("id", "data_collection_period"))

# Append Year 1 functional independence scores and coalesce variables shared between TBIMS Form 1 and Form 2
merged_data <- merged_data |>
  # left_join(function_factor_scores |> select(id, func), by = "id") |>
  left_join(function_factor_scores, by = "id") |>
  rename(func_score_at_year_1 = func) |>
  mutate(
    date_of_death = coalesce(date_of_death.x, date_of_death.y),
    cause_of_death_1 = coalesce(cause_of_death_1.x, cause_of_death_1.y),
    cause_of_death_2 = coalesce(cause_of_death_2.x, cause_of_death_2.y),
    cause_of_death_e = coalesce(cause_of_death_e.x, cause_of_death_e.y)
 )
```

```{r Create the Variable Corresponding to the Date of Each Participant's Year 1 Follow-Up Interview}
# Create the date_of_year_1_followup and impute it
merged_data <- merged_data |>
  # Create the date_of_year_1_followup variable
  left_join(
    merged_data |>
      filter(data_collection_period == 1) |>
      group_by(id) |>
      summarise(date_of_year_1_followup = if (all(is.na(date_of_followup))) NA else min(date_of_followup, na.rm = TRUE)) |>
      filter(!is.na(date_of_year_1_followup)), # Remove rows where date_of_year_1_followup is NA
    by = "id"
  ) |>
  # Impute the date_of_year_1_followup to all subsequent observations per id
  group_by(id) |>
  fill(date_of_year_1_followup, .direction = "downup")
```

```{r Create a Sample Data Frame, include = FALSE}
# # List of IDs to subset
# ids_to_select <- c(22, 9345, 10468, 11911, 13806, 15546, 17398)
# 
# # Subset the merged_data data frame
# sample_data <- merged_data |>
#   filter(id %in% ids_to_select) |>
#   select(id, data_collection_period, date_of_year_1_followup, date_of_followup) |>
#   arrange(id, data_collection_period)
```

The `combine_value_labels` function is designed to combine the value labels from two different variables into a single set of labels. This function is particularly useful when dealing with variables that have been coalesced from multiple data sources that need a unified set of value labels. The function takes two arguments, `var` and `var2`, which are the variables for which you want to combine the labels. The function then returns a unified list of de-duplicated labels across these variables.

The `update_labels_with_sjlabelled` function is used to update the value labels of factor variables within a data frame based on their current levels. It's particularly useful as a pre-processing step to ensure that the value labels are consistent with the actual data after they have undergone various transformations. This function takes two arguments: `data`, the data frame to be processed, and `mapping_lists`, a list of mappings that specify how to handle each variable in the dataframe. The function iteratively updates each factor variable's labels to ensure that they align with the data present after various transformations.

```{r Define a Function to Update Value Labels}
#' Update value labels of factor variables defined in mapping lists
#'
#' This function updates value labels of factor variables defined in mapping lists.
#'
#' @param data A data frame.
#' @param mapping_lists A list of mapping rules.
#' @return An updated data frame.
#' @export
#' @examples
#' update_labels_with_sjlabelled(mtcars, list(cyl = list(na_values = c(4, 6), original_name = "cyl", to_class = "factor")))
update_labels_with_sjlabelled <- function(data, mapping_lists) {
  # Loop through each mapping list
  for (mapping_list in mapping_lists) {
    # Loop through each variable in the mapping list
    for (var_name in names(mapping_list)) {
      # Process only factor variables
      if (is.factor(data[[var_name]])) {
        # Retrieve original labels with numeric values for the variable
        original_labels <- get_labels(data[[var_name]], values = "n")
        # Get current factor levels of the variable
        current_levels <- levels(data[[var_name]])
        # Create a named vector of labels based on current levels
        valid_labels <- original_labels[names(original_labels) %in% current_levels]
        # Update the variable in the dataframe with the new set of labels
        data[[var_name]] <- set_labels(data[[var_name]], labels = valid_labels)
      }
    }
  }
  # Return the updated dataframe
  return(data)
}
```

```{r Update Desired Value Labels}
# Update value labels of variables in the mapping lists
merged_data <- update_labels_with_sjlabelled(merged_data, list(baseline_name_and_na_mappings, followup_name_and_na_mappings))
```

```{r Process the Factor Variables in the Merged Data}
merged_data <- merged_data |>
# Perform additional calculations, collapse factor levels, and convert data types
  mutate(
    # Calculate age at time of injury (if missing)
    age_at_injury= if_else(is.na(age_at_injury), floor(as.duration(interval(date_of_birth, date_of_injury))/dyears(1)), age_at_injury),
    
    # Specify the value labels associated with follow-up interview status
    status_at_followup = fct_recode(status_at_followup,
                                    Followed = "1",
                                    Lost = "2",
                                    Refused = "3",
                                    Incarcerated = "4",
                                    Withdrew = "5",
                                    Expired = "6",
                                    "No Funding" = "7"),
    
    # Set 'Male' as the reference group for sex
    sex = fct_recode(sex,
                     Female = "1",
                     Male = "2"
                     ) |>
    fct_relevel("Male", "Female"),
    
    # Collapse and reorder the levels of the cause of injury covariate
    cause_of_injury = fct_recode(cause_of_injury,
                                 "Motor Vehicle" = "1",
                                 Motorcycle = "2",
                                 Bicycle = "3",
                                 "All-Terrain Vehicle (ATV) and All-Terrain Cycle (ATC)" = "4",
                                 "Other Vehicular: Unclassified" = "5",
                                 "Gunshot Wound" = "10",
                                 "Assaults With Blunt Instrument" = "11",
                                 "Other Violence" = "12",
                                 "Water Sports" = "13",
                                 "Field/Track Sports" = "14",
                                 "Gymnastic Activities" = "15",
                                 "Winter Sports" = "16",
                                 "Air Sports" = "17",
                                 "Other Sports" = "18",
                                 "Fall" = "19",
                                 "Hit By Falling/Flying Object" = "20",
                                 "Pedestrian" = "21",
                                 "Other Unclassified" = "22"
                                 ) |>
      fct_collapse(
        Vehicular = c("Motor Vehicle", "Motorcycle", "Bicycle", "All-Terrain Vehicle (ATV) and All-Terrain Cycle (ATC)",
                      "Other Vehicular: Unclassified"),
        Falls = "Fall",
        Violence = c("Gunshot Wound", "Assaults With Blunt Instrument", "Other Violence"),
        Other = c("Water Sports", "Field/Track Sports", "Gymnastic Activities", "Winter Sports", "Air Sports",
                  "Other Sports", "Hit By Falling/Flying Object", "Pedestrian", "Other Unclassified")
      ) |>
      # Set 'Vehicular' as the reference group for cause of injury
      fct_relevel("Vehicular", "Falls", "Violence", "Other"),
    
    # Collapse and reorder the levels of the marital status at injury covariate
    marital_status_at_injury = fct_recode(marital_status_at_injury,
                                          "Single (Never Married)" = "1",
                                          Married = "2",
                                          Divorced = "3",
                                          Separated = "4",
                                          Widowed = "5",
                                          Other = "7"
                                          ) |>
      fct_collapse(
        Single = "Single (Never Married)",
        Married = "Married",
        Divorced = "Divorced",
        Other = c("Separated", "Widowed", "Other")
      ) |>
      # Set 'Single' as the reference group for marital status at injury
      fct_relevel("Single", "Married", "Divorced", "Other"),
    
    # Collapse and reorder the levels of 'EMPLOYMENT'
    employment_at_injury = employment_at_injury |>
      fct_recode(
        "Full Time Student" = "2",
        "Part Time Student" = "3",
        "Special Education" = "4",
        "Competitively Employed" = "5",
        "Homemaker" = "7",
        "Special Employed" = "8",
        Retired = "9",
        Unemployed = "10",
        Volunteer = "11",
        Other = "12"
      ) |>
      fct_collapse(
        "Competitively Employed" = "Competitively Employed",
        Unemployed = "Unemployed",
        Student = c("Full Time Student", "Part Time Student", "Special Education"),
        Retired = "Retired",
        Other = c("Special Employed", "Homemaker", "Volunteer", "Other")
      ) |>
      # Set 'Competitively Employed' as the reference group for employment status at injury
      fct_relevel("Competitively Employed", "Unemployed", "Student", "Retired", "Other"),
    
    # Add the SES proxy covariate based on primary health insurance coverage for rehabilitation services
    rehab_payor_primary_type = if_else(rehab_payor_primary == "2", 1, 0),
    rehab_payor_primary_type = factor(rehab_payor_primary_type, levels = c(0, 1), labels = c("Non-Medicaid", "Medicaid")),
    
    # Collapse and reorder the levels of the primary rehabilitation payor covariate
    rehab_payor_primary = rehab_payor_primary |>
      fct_recode(
        Medicare = "1",
        Medicaid = "2",
        "Workers Compensation" = "3",
        "Private Insurance" = "4",
        "Self or Private Pay" = "7",
        "State or County" = "8",
        "Auto Insurance" = "10",
        Charity = "14",
        Other = "15",
        "Payor Source Pending" = "55"
      ) |>
      fct_collapse(
        "Private Insurance" = c("Private Insurance", "Workers Compensation", "Auto Insurance"),
        "Public Insurance" = c("Medicaid", "Medicare", "State or County"),
        Other = c("Self or Private Pay", "Charity", "Payor Source Pending", "Other")
      ) |>
      # Set 'Private Insurance' as the reference group for Medicaid status
      fct_relevel("Private Insurance", "Public Insurance", "Other"),
    
    # Set 'No' as the reference group for the problematic substance use at time of injury covariate
    problematic_substance_use_at_injury = fct_recode(problematic_substance_use_at_injury,
                                                     No = "0",
                                                     Yes = "1"
                                                     ) |>
    fct_relevel("No", "Yes"),
    
    # Set 'No' as the reference group for the problematic substance use at follow-up covariate
    problematic_substance_use_at_followup = fct_recode(problematic_substance_use_at_followup,
                                                       No = "0",
                                                       Yes = "1"
                                                       ) |>
    # Set 'No' as the reference group for problematic substance use at follow-up
    fct_relevel("No", "Yes"),
    
    # Set 'No' as the reference group for the lifetime hx of mental health treatment at time of injury covariate
    mental_health_tx_lifetime_at_injury = fct_recode(mental_health_tx_lifetime_at_injury,
                                                     No = "0",
                                                     Yes = "1"
                                                     # "Not Applicable" = "88"  # '88' code not present in current dataset
                                                     ) |>
    fct_relevel("No", "Yes"),
      
    # Set 'No' as the reference group for the past-year hx of mental health treatment at time of injury covariate
    mental_health_tx_past_year_at_injury = fct_recode(mental_health_tx_past_year_at_injury,
                                                      No = "0",
                                                      Yes = "1",
                                                      "Not Applicable" = "88"  # '88' code not present in current dataset
                                                      ) |>
      fct_collapse(
        No = c("No", "Not Applicable"),
        Yes = "Yes"
        ) |>
      fct_relevel("No", "Yes"),
    
    # Set 'No' as the reference group for the lifetime hx of psychiatric hospitalization at time of injury covariate
    psych_hosp_hx_lifetime_at_injury = fct_recode(psych_hosp_hx_lifetime_at_injury,
                                                  No = "0",
                                                  Yes = "1",
                                                  "Not Applicable" = "88"
                                                  ) |>
      fct_collapse(
        No = c("No", "Not Applicable"),
        Yes = "Yes"
        ) |>
      fct_relevel("No", "Yes"),
    
    # Set 'No' as the reference group for the past-year hx of psychiatric hospitalization at time of injury covariate
    psych_hosp_hx_past_year_at_injury = fct_recode(psych_hosp_hx_past_year_at_injury,
                                                   No = "0",
                                                   Yes = "1",
                                                   "Not Applicable" = "88"
                                                   ) |>
      fct_collapse(
        No = c("No", "Not Applicable"),
        Yes = "Yes"
        ) |>
      fct_relevel("No", "Yes"),

    # Set 'No' as the reference group for the past-year hx of suicide attempt at time of injury covariate
    suicide_attempt_hx_lifetime_at_injury = fct_recode(suicide_attempt_hx_lifetime_at_injury,
                                              No = "0",
                                              Yes = "1",
                                              ) |>
      fct_relevel("No", "Yes"),
    
    # Set 'No' as the reference group for the past-year hx of suicide attempt at time of injury covariate
    suicide_attempt_hx_past_year_at_injury = fct_recode(suicide_attempt_hx_past_year_at_injury,
                                              No = "0",
                                              Yes = "1",
                                              "Not Applicable" = "88"
                                              ) |>
      fct_collapse(
        No = c("No", "Not Applicable"),
        Yes = "Yes"
        ) |>
      fct_relevel("No", "Yes"),
    
    # Set 'No' as the reference group for the past-year hx of suicide attempt at follow-up covariate
    suicide_attempt_hx_past_year_at_followup = fct_recode(suicide_attempt_hx_past_year_at_followup,
                                                          No = "0",
                                                          Yes = "1",
                                                          ) |>
      fct_relevel("No", "Yes")
  ) |>
  
  droplevels()  # Drop unused factor levels
```

```{r Carry Baseline Variables Forward to Subsequent Observations while Maintaining Factor Labels}
# List of baseline variables to carry forward to subsequent observations via LOCF
baseline_vars <- c(
  "date_of_birth",
  "date_of_injury",
  "sex",
  "age_at_injury",
  "cause_of_injury", 
  "marital_status_at_injury", 
  "education_level_at_injury",
  "employment_at_injury",
  "rehab_payor_primary",
  "rehab_payor_primary_type",
  "problematic_substance_use_at_injury",
  "mental_health_tx_lifetime_at_injury",
  "mental_health_tx_past_year_at_injury",
  "psych_hosp_hx_lifetime_at_injury",
  "psych_hosp_hx_past_year_at_injury",
  "suicide_attempt_hx_lifetime_at_injury",
  "suicide_attempt_hx_past_year_at_injury"
)

# Store original factor levels and labels before applying the LOCF fill to baseline variables
original_factor_info <- list()
for (var in baseline_vars) {
  if (is.factor(merged_data[[var]])) {
    original_factor_info[[var]] <- list(
      levels = levels(merged_data[[var]]),
      labels = get_labels(merged_data[[var]], values = "n")
    )
  }
}

# Convert factors to characters before applying the LOCF fill to baseline variables
merged_data <- merged_data |>
  mutate(across(all_of(baseline_vars), ~ if (is.factor(.)) { as.character(.) } else { . })) |>
  # Perform the LOCF fill of baseline variable data to all subsequent observations
  group_by(id) |>
  fill(!!!syms(baseline_vars), .direction = "down") |>
  ungroup()

# Convert characters back to factors with original factor levels, then set the factor labels using 'set_labels'
for (var in names(original_factor_info)) {
  if (!is.null(original_factor_info[[var]])) {
    levels_info <- original_factor_info[[var]]$levels
    labels_info <- original_factor_info[[var]]$labels

    # Convert back to factor
    merged_data[[var]] <- factor(merged_data[[var]], levels = levels_info)

    # Set labels using set_labels from sjlabelled
    merged_data[[var]] <- set_labels(merged_data[[var]], labels = setNames(levels_info, labels_info))
  }
}
```

```{r Select and Arrange the Final Data Columns in the Merged Data Frame}
# Select and reorder merged data columns
merged_data <- merged_data |>
  select(
    id,
    status_at_followup,
    data_collection_period,
    date_of_year_1_followup,
    date_of_followup,
    date_of_death,
    date_of_birth,
    date_of_injury,
    sex,
    age_at_injury,
    cause_of_injury,
    cause_of_death_1,
    cause_of_death_2,
    cause_of_death_e,
    marital_status_at_injury,
    education_level_at_injury,
    employment_at_injury,
    rehab_payor_primary,
    rehab_payor_primary_type,
    drs_total_at_followup,
    fim_total_at_followup,
    gose_total_at_followup,
    drs_total_at_year_1,
    fim_total_at_year_1,
    gose_total_at_year_1,
    func_score_at_year_1,
    mental_health_tx_lifetime_at_injury,
    mental_health_tx_past_year_at_injury,
    psych_hosp_hx_lifetime_at_injury,
    psych_hosp_hx_past_year_at_injury,
    problematic_substance_use_at_injury,
    problematic_substance_use_at_followup,
    suicide_attempt_hx_lifetime_at_injury,
    suicide_attempt_hx_past_year_at_injury,
    suicide_attempt_hx_past_year_at_followup,
    phq1, phq2, phq3, phq4, phq5, phq6, phq7, phq8, phq9
    ) |>
  arrange(id, data_collection_period)
```

# Define Logging Functions

The following function is designed to record the size of a study sample after applying a specific study eligibility criterion. Essentially, this function tracks the number of participants who remain in the sample after each stage of filtering. First, it ensures that the specified log directory exists, creating it if necessary. It then calculates the number of unique participant IDs that remain in the dataset as well as the total number of observations or rows that remain in the dataset after applying the study eligibility criterion. These values are then stored in a log file named 'sample_sizes.log' within the specified directory.

```{r Define a Function to Log the Sample Sizes After Applying Each Study Eligibility Criterion}
#' Log Sample Size After Applying Study Eligibility Criteria
#'
#' This function logs the updated sample size after applying a specific study eligibility criterion.
#'
#' @param data A data frame representing the study data after applying the criterion.
#' @param criterion_number An integer representing the sequence number of the applied criterion.
#' @param base_directory A string indicating the directory where the log file will be stored. 
#'        Default is "logs".
#'
#' @details
#' The function performs the following steps:
#' 1. Ensures the existence of the specified logging directory.
#' 2. Creates or accesses a log file named 'sample_sizes.log' within this directory.
#' 3. Calculates and logs the number of unique participant IDs and the total number 
#'    of observations in the data that remain after applying the study eligibility criterion.
#'
#' @examples
#' # Log sample size for criterion 1 in default directory
#' log_sample_size(my_data, 1)
#'
#' # Log sample size for criterion 2 in a custom directory
#' log_sample_size(my_data, 2, "custom_logs")
#'
#' @export
log_sample_size <- function(data, criterion_number, base_directory = "logs") {
  # Ensure the 'logs' directory exists
  dir.create(base_directory, showWarnings = FALSE)

  # Create the log file name
  log_file <- file.path(base_directory, "sample_sizes.log")

  # Calculate the number of unique IDs and total observations
  unique_ids <- length(unique(data$id))
  total_observations <- nrow(data)

  # Construct the log message
  message <- sprintf("Criterion %d: Unique IDs = %d, Total Observations = %d\n", 
                     criterion_number, unique_ids, total_observations)

  # Append the message to the log file
  cat(message, file = log_file, append = TRUE)
}
```

```{r Log Sample Sizes with Original Sample Size Included}
log_sample_size <- function(data, criterion_number, base_directory = "logs", original_data = NULL) {
  # Ensure the 'logs' directory exists
  dir.create(base_directory, showWarnings = FALSE)

  # Create the log file name
  log_file <- file.path(base_directory, "sample_sizes.log")

  # Calculate the number of unique IDs and total observations
  unique_ids <- length(unique(data$id))
  total_observations <- nrow(data)
  
  # Calculate the number of unique participants in the original dataset if provided
  if (!is.null(original_data)) {
    original_unique_ids <- length(unique(original_data$id))
  } else {
    original_unique_ids <- NA
  }

  # Format the numbers with commas
  original_unique_ids_formatted <- ifelse(is.na(original_unique_ids), "NA", format(original_unique_ids, big.mark = ","))
  unique_ids_formatted <- format(unique_ids, big.mark = ",")
  total_observations_formatted <- format(total_observations, big.mark = ",")
  
  # Construct the log message
  message <- sprintf("Original Unique IDs: %s\n Unique IDs after Applying Criterion %d: %s\n Total Observations after Applying Criterion %d: %s\n\n", 
                     original_unique_ids_formatted, criterion_number, unique_ids_formatted, criterion_number, total_observations_formatted)
  
  # Append the message to the log file
  cat(message, file = log_file, append = TRUE)
}
```


The following function is designed to record the participant IDs of participants who were removed from the study sample after applying a specific study eligibility criterion. First, the function ensures that the specified log directory exists, creating it if necessary. It then determines the participant IDs that were present in the original dataset but absent in the filtered dataset, indicating their removal from the sample due to failure to fulfill the study eligibility criterion. These removed participant IDs are then stored in a log file named 'criterion\_\[number\]\_removed_ids.log' within the specified directory, where "\[number\]" is adjusted to match the specific criterion number.

```{r Define a Function to Log the Number of Participants Removed after Applying Each Study Eligibility Criterion}
#' Log Removed Participant IDs After Applying Study Eligibility Criteria
#'
#' This function logs the IDs of participants who were removed during the application of a specific study eligibility criterion.
#'
#' @param original_data The original dataset before applying the criterion.
#' @param filtered_data The dataset after applying the criterion.
#' @param criterion_number An integer indicating the sequence number of the applied criterion.
#' @param base_directory A string specifying the directory for the log files. 
#'        Default is "logs".
#'
#' @details
#' The function identifies which participant IDs were removed by the criterion and 
#' logs them in a file named "criterion_[number]_removed_ids.log".
#'
#' @examples
#' # Log removed IDs for criterion 1
#' log_removed_ids(my_original_data, my_filtered_data, 1)
#'
#' # Log removed IDs for criterion 2 in a custom directory
#' log_removed_ids(my_original_data, my_filtered_data, 2, "custom_logs")
#'
#' @export
log_removed_ids <- function(original_data, filtered_data, criterion_number, base_directory = "logs") {
  # Ensure the 'logs' directory exists
  dir.create(base_directory, showWarnings = FALSE)

  # Find IDs removed by the criterion
  removed_ids <- setdiff(unique(original_data$id), unique(filtered_data$id))

  # Convert removed IDs to character vector
  removed_ids_char <- as.character(removed_ids)

  # Create the log file name
  log_file <- file.path(base_directory, sprintf("criterion_%d_removed_ids.log", criterion_number))

  # Write the removed IDs to the log file
  writeLines(removed_ids_char, log_file)
}
```

### Define a Helper Function to Dynamically Calculate Each Participant's End Date

```{r Define a Helper Function to Dynamically Calculate Each Participants End Date}
#' Check if Follow-up Date is Within Study Period
#'
#' This function checks if the follow-up date for a participant is within the study period,
#' which is defined as the period starting from a globally defined `study_entry_period_start_date`
#' and ending 10 years after the participant's date of the first follow-up interview.
#'
#' @param date_of_year_1_followup Date. The date of the first follow-up interview for the participant.
#' @param date_of_followup Date. The date of follow-up for the participant.
#'
#' @return Logical. Returns `TRUE` if the follow-up date is within the study period, `FALSE` otherwise.
#' 
#' @examples
#' # Assume study_entry_period_start_date is defined globally as '2000-01-01'
#' study_entry_period_start_date <- as.Date('2000-01-01')
#' is_within_study_period(as.Date('2005-06-15'), as.Date('2001-06-15')) # Returns TRUE
#' is_within_study_period(as.Date('2012-06-15'), as.Date('2001-06-15')) # Returns FALSE
#'
#' @export
# Define a function to dynamically calculate each participant's end date
is_within_study_period <- function(date_of_year_1_followup, date_of_followup) {
  participant_end_date <- date_of_year_1_followup + years(5)
  !is.na(date_of_followup) & date_of_followup >= study_entry_period_start_date & date_of_followup <= participant_end_date
}
```

The `apply_labels_to_renamed_vars` function is used to assign stored variable labels to renamed variables in a dataset. In this particular case, it enables us to rename the variables according to tidyverse style guidelines while retaining all original meaningful descriptors The function first unlists the baseline and follow-up labels to flatten them for easier manipulation and then iterates through each mapping rule in `baseline_mappings` and `followup_mappings` to locate the corresponding old name for each new variable name and then applying the appropriate label from `baseline_labels` and `followup_labels` to the new variable names in `merged_data`.

```{r Define a Function to Apply Original Variable Labels to Renamed Variables}
#' Apply original variable labels to renamed variables
#'
#' This function applies stored variable labels to renamed variables.
#'
#' @param merged_data A data frame.
#' @param baseline_labels A vector of variable labels for baseline variables.
#' @param followup_labels A vector of variable labels for follow-up variables.
#' @param baseline_mappings A list of mapping rules for baseline variables.
#' @param followup_mappings A list of mapping rules for follow-up variables.
#' @return A data frame with labels applied to renamed variables.
#' @export
#' @examples
#' apply_labels_to_renamed_vars(mtcars, c("Baseline MPG", "Baseline Cylinders"), c("Follow-up MPG", "Follow-up Cylinders"), list(cyl = list(original_name = "cylinders")), list(mpg = list(original_name = "mpg")))
apply_labels_to_renamed_vars <- function(merged_data, baseline_labels, followup_labels, baseline_mappings, followup_mappings) {
  # Unlist the labels
  baseline_labels_unlisted <- unlist(baseline_labels)
  followup_labels_unlisted <- unlist(followup_labels)

  # Apply TBIMS Form 1 (baseline) labels
  for (new_name in names(baseline_mappings)) {
    original_name <- baseline_mappings[[new_name]]$original_name
    if (!is.null(baseline_labels_unlisted[original_name])) {
      var_label(merged_data[[new_name]]) <- baseline_labels_unlisted[original_name]
    }
  }

  # Apply TBIMS Form 2 (follow-up) labels
  for (new_name in names(followup_mappings)) {
    original_name <- followup_mappings[[new_name]]$original_name
    if (!is.null(followup_labels_unlisted[original_name])) {
      var_label(merged_data[[new_name]]) <- followup_labels_unlisted[original_name]
    }
  }

  return(merged_data)
}
```

# Apply Study Eligibility Criteria and Log the Results

The three following functions are part of a series of steps that ensure the analytic sample is comprised only of participants meeting the study eligibility criteria.

## Study Eligibility Criterion 1 (Inclusion): Injured between 2006-10-01 and 2012-10-01

The `apply_criterion_1` function is designed to filter and process data based on the first study eligibility criterion, which entails that the retained data were collected within the defined study observation period. The function also accounts for special cases in which the full follow-up interview was not administered.

**Filtering by Date** First, the function retains data from participants whose dates of injury fell within the start and end dates of the observation period. **Grouping and Flagging** The function then groups the data by participant ID and creates flags for follow-up validity and special cases (e.g., "Lost," "Refused," etc.). The `valid_followup` flag is set to `TRUE` if either `date_of_followup` or `date_of_death` contain a date value that falls within the study period and `FALSE` otherwise. The `special_case` flag identifies observations with special circumstances based on the `status_at_followup` field; observations are flagged as special cases if this variable is one of the following: "Lost," "Refused," "Incarcerated," "Withdrew," or "No Funding." These interview statuses indicate situations where standard follow-up might not have been possible or reliable, requiring separate handling in the analysis.

**Inclusion Criteria** The function uses a combination of these flags and the `data_collection_period` to determine whether an observation should be included in the returned data frame. The inclusion is based on several factors:

1.  Data Collection Period: If the `data_collection_period` is 0 (indicating baseline data), the observation is retained.
2.  Follow-Up Validity and Special Cases:

-   For follow-up data, an observation's inclusion in the returned data frame depends on the values of:
-   `valid_followup`: If this flag is `TRUE`, it means the observation contains a valid date in either the date of follow-up date or date of expiration columns, thus making the observation relevant to the study; or
-   `special_case`: This flags observations with special interview statuses (like "Lost," "Refused," etc.); if this flag is `TRUE`, then the respective observation is retained only if its subsequent follow-up observation (checked using `lead(valid_followup, default = FALSE)`) is valid.
-   These approaches ensure that the returned dataset retains baseline observations and follow-up observations that are either valid within the study period or are special cases with valid subsequent follow-up data.

**Event Status and Time to Event** This section of the function calculates two important pieces of information for the survival analysis: 1. **Event Status (`event_status`):** - This is a binary indicator (0 or 1) indicating whether a significant event (i.e., mortality) occurred prior to the study end date. - This variable is calculated using `if_else(!is.na(date_of_death) & date_of_death <= participant_end_date, 1, 0)`, where `event_status` is set to 1 (indicating that the event occurred) if `date_of_death` is not missing (`!is.na(date_of_death)`) and occurred on or before the study end date; otherwise, it is set to 0. 2. **Time to Event (`time_to_event`):** - This represents the time (in days) from the date of injury to the event or the last valid follow-up date. - This variable is calculated differently for baseline and follow-up observations: - For baseline (`data_collection_period == 0`), the time to event is set to 0. - For follow-up observations, `time_to_event` is the number of days between the date of injury and the later of either the follow-up date or the date of death, computed using `case_when(...)`. The `pmax(date_of_followup, date_of_death, na.rm = TRUE)` function finds the latest of these two dates within a given observation, and `as.numeric(last_valid_date - date_of_injury, units = "days")` calculates the time difference in days. 3. **`time_to_censorship` and `time_to_expiration`:** - These lines compute two new variables, `time_to_expiration` and `time_to_censorship`. The calculations for these variables are based on the dates of injury, follow-up, and death for each observation. Consideration is given to whether or not each observation is the last observation for a given `id`; if it is, then the `time_to_expiration` calculation is prioritized (assuming a valid date is entered for `date_of_death`); if additional observations exist for the current participant, then the `time_to_censorship` calculation is prioritized (assuming a valid date is entered for `date_of_followup`). The `dplyr` and `lubridate` packages facilitate data manipulation and date calculations, respectively. The result is a modified data frame that includes the two new variables.

Based on the data collection period and the flags set previously, the function determines which observations to include in the returned data frame. Event status is then determined based on the availability of valid date data in the `date_of_death` column (in which case, `event_status` = 1); if the column contains NA, then `event_status` is set to 0. Each participant's time to event (i.e., time to censorship or time to death) is then calculated

```{r Define a Function to Apply Study Eligibility Criterion 1 (Inclusion): Injured between October 1, 2006 and October 1, 2012 with Follow-Up for Up to 10 Years Post-Injury}
#' Apply Study Eligibility Criterion 1
#'
#' This function applies a specified study eligibility criterion (Criterion 1) to filter 
#' and transform clinical research data. It includes observations within a specified 
#' period, accounts for special cases, and computes each participant's event status and
#' time to event.
#'
#' @param data A data frame containing the clinical research data.
#' @param study_entry_period_start_date The start date of the observation period (inclusive).
#' @param study_entry_period_end_date The end date of the observation period (inclusive).
#' @return A data frame filtered and transformed according to Criterion 1, which includes variables for event status and time to event.
#' @examples
#' # To use the function, provide a data frame and relevant dates:
#' apply_criterion_1(data, "2020-01-01", "2021-01-01")
#' @export
apply_criterion_1 <- function(data, study_entry_period_start_date, study_entry_period_end_date) {
  original_data <- data  # Store the original data for logging removed IDs
  
  data <- data |>
    filter(date_of_year_1_followup >= study_entry_period_start_date & date_of_year_1_followup <= study_entry_period_end_date) |>
    arrange(id, date_of_followup, date_of_death) |>
    group_by(id) |>
    mutate(
      # study_end_date = date_of_year_1_followup + years(5),
      participant_end_date = date_of_year_1_followup + years(5),
      valid_followup = is_within_study_period(date_of_year_1_followup, date_of_followup) | 
        is_within_study_period(date_of_year_1_followup, date_of_death),
      special_case = status_at_followup %in% c("Lost", "Refused", "Incarcerated", "Withdrew", "No Funding"),
      include_observation = if_else(data_collection_period == 0, TRUE, valid_followup | (special_case & lead(as.logical(valid_followup, default = FALSE)))),
      calendar_year_of_event = if_else(!is.na(date_of_death), year(date_of_death),
                                       if_else(!is.na(date_of_followup), year(date_of_followup), NA_integer_)),
      calendar_year_of_injury = year(date_of_injury)
    ) |>
    filter(include_observation) |>
    mutate(
      # event_status = if_else(!is.na(date_of_death) & date_of_death <= study_end_date, 1, 0),
      event_status = if_else(!is.na(date_of_death) & date_of_death <= participant_end_date, 1, 0),
      time_to_censorship = if_else(is.na(date_of_death) & is.na(date_of_followup), 0, 
                                   if_else(!is.na(date_of_followup), as.numeric(difftime(date_of_followup, date_of_year_1_followup, units = "days")), NA_real_)),
      time_to_expiration = if_else(is.na(date_of_death) & is.na(date_of_followup), 0, 
                                   if_else(!is.na(date_of_death), as.numeric(difftime(date_of_death, date_of_year_1_followup, units = "days")), NA_real_)),
      time_to_event = if_else(!is.na(date_of_death), time_to_expiration,
                              if_else(!is.na(time_to_censorship), time_to_censorship, NA_real_))
    ) |>
    ungroup() |>
    select(id, data_collection_period, status_at_followup, event_status,
           time_to_event, time_to_censorship, time_to_expiration,
           calendar_year_of_injury, calendar_year_of_event, date_of_year_1_followup,
           date_of_followup, date_of_death, participant_end_date, everything()) |>
    select(-valid_followup, -special_case, -include_observation) |>
    arrange(id, data_collection_period)
  
  # Log the sample size after applying Criterion 1
  log_sample_size(data, 1, "logs", original_data)

  # Log the removed IDs
  log_removed_ids(original_data, data, 1)

  return(data)
}
```

## Study Eligibility Criterion 2 (Exclusion): Early Mortality and Negative Survival Times

The `apply_criterion_2` function is designed to further refine the analytic sample based on the second study eligibility criterion, which excludes participants who exhibited early mortality (i.e., death on the date of injury, as indicated by `time_to_event == 0`) or negative survival times (which is most likely attributable to data entry errors). The function receives the `data` data frame as the input and filters out any observations for which the `time_to_event` variable--which represents the time from the date of injury to the date of either follow-up or expiration--is missing or negative. After filtering, the function logs the number of participants remaining in the sample and the IDs of those who were removed due to this study eligibility criterion. The function returns the modified dataset, now excluding the removed participants.

```{r Define a Function to Apply Study Eligibility Criterion 2 (Exclusion): Remove Cases with Early Mortality or a Negative Survival Time}
#' Apply Study Eligibility Criterion 2
#'
#' This function filters the input dataset based on specific criteria 
#' related to `time_to_event` and `data_collection_period`. It retains rows 
#' where the `time_to_event` is greater than 0 or where the `data_collection_period` 
#' is 1 and the row is not the last observation for that `id`. The function then logs 
#' the sample size and the IDs of the removed rows.
#'
#' @param data A data frame containing the dataset to be filtered. It should have 
#' columns `id`, `time_to_event`, and `data_collection_period`.
#'
#' @return A data frame that has been filtered according to the criteria.
#'
#' @details
#' The function performs the following steps:
#' 1. Stores the original dataset for logging purposes.
#' 2. Groups the data by `id`.
#' 3. Creates a temporary column `last_observation` to identify the last row for each `id`.
#' 4. Filters the rows based on the specified criteria:
#'    - `time_to_event` > 0
#'    - `data_collection_period` == 1 and not the last observation for that `id`
#' 5. Removes the temporary `last_observation` column.
#' 6. Logs the sample size after filtering.
#' 7. Logs the IDs of the removed rows.
#'
#' @examples
#' \dontrun{
#' # Assuming 'df' is your input data frame
#' filtered_data <- apply_criterion_2(df)
#' }
#'
#' @export
apply_criterion_2 <- function(data) {
  original_data <- data  # Store the original data for logging the removed IDs

  data <- data |>
    group_by(id) |>
    mutate(last_observation = row_number() == n()) |>
    filter(time_to_event > 0 | data_collection_period == 1 & !last_observation) |>
    ungroup() |>
    select(-last_observation)

  # Log the sample size after applying Criterion 2
  log_sample_size(data, 2)

  # Log the removed IDs
  log_removed_ids(original_data, data, 2)

  return(data)
}
```

## Study Eligibility Criterion 3 (Inclusion): Determinate Date Data for Calculating Survival Times

The `apply_criterion_3` function is designed to apply the final study eligibility criterion, which requires that all participants have the necessary date data for the calculation of survival times. This function requires the specification of the data frame (`data`) as well as the parameters `tbims_form1_labels`, `tbims_form2_labels`, `baseline_name_and_na_mappings`, and `followup_name_and_na_mappings`, which contain additional information about variable labels and mappings for baseline and follow-up data. The function starts by grouping data by participant ID and filtering out those without a valid follow-up or expiration date (`last_valid_date`). These dates are essential for calculating survival times. Next, the function applies the original TBIMS Form 1 and Form 2 labels to the renamed variables, using the mappings provided in the additional parameters. As in the previous functions, the sample size log is then updated with the new sample size after applying this criterion, and the IDs of excluded participants are logged. The final output is a dataset with participants who fulfilled all three study eligibility criteria, with appropriately labeled variables.

```{r Define a Function to Apply Study Eligibility Criterion 3 (Inclusion): Availability of Determinate Date Data for Calculating Survival Time}
#' Apply Study Eligibility Criterion 3
#'
#' This function applies the third study eligibility criterion, focusing on the 
#' inclusion of participants with determinate date data available for calculating survival times.
#'
#' @param data A data frame containing the study data.
#' @param tbims_form1_labels Labels for baseline variables from TBIMS Form 1.
#' @param tbims_form2_labels Labels for follow-up variables from TBIMS Form 2.
#' @param baseline_name_and_na_mappings Mappings for renamed baseline variables.
#' @param followup_name_and_na_mappings Mappings for renamed follow-up variables.
#' @return A data frame after applying Criterion 3, with only eligible observations included.
#' @details
#' The function performs the following operations:
#' 1. Filters out observations without a valid follow-up or death date for calculating survival time.
#' 2. Applies original variable labels to renamed variables based on TBIMS Form 1 and 2 labels.
#' 3. Logs the sample size and IDs of participants removed after applying this criterion.
#' 4. Returns the modified dataset.
#' @examples
#' # Apply Criterion 3 to a dataset
#' modified_data <- apply_criterion_3(dataset, tbims_form1_labels, tbims_form2_labels, 
#'                                    baseline_name_and_na_mappings, followup_name_and_na_mappings)
#' @export
apply_criterion_3 <- function(data, tbims_form1_labels, tbims_form2_labels, baseline_name_and_na_mappings, followup_name_and_na_mappings) {
  original_data <- data  # Store the original data for logging removed IDs

  data <- data |>
    arrange(id, date_of_followup, date_of_death) |>
    group_by(id) |>
    mutate(
      is_last_observation = lead(id, default = last(id)) != id,
      last_valid_date = pmax(date_of_followup, date_of_death, na.rm = TRUE)
    ) |>
    filter(any(!is.na(last_valid_date))) |>
    ungroup() |>
    select(-is_last_observation, -last_valid_date)

  # Apply original variable labels to renamed variables
  data <- apply_labels_to_renamed_vars(
    data, 
    tbims_form1_labels, 
    tbims_form2_labels, 
    baseline_name_and_na_mappings, 
    followup_name_and_na_mappings
  )

  # Log the sample size after applying Criterion 3
  log_sample_size(data, 3)

  # Log the removed IDs
  log_removed_ids(original_data, data, 3)

  return(data)
}
```

## Call the Study Eligibility Criteria Functions

```{r Call the study eligibility criteria functions}
# Apply Study Eligibility Criterion 1
analytic_data <- apply_criterion_1(merged_data, study_entry_period_start_date, study_entry_period_end_date)

# Apply Study Eligibility Criterion 2
analytic_data <- apply_criterion_2(analytic_data)

# Apply Study Eligibility Criterion 3
analytic_data <- apply_criterion_3(analytic_data, tbims_form1_labels, tbims_form2_labels, baseline_name_and_na_mappings, followup_name_and_na_mappings)
```

### Create a Sample Data Frame of the Analytic Data

```{r Create a sample data frame of the analytic dataset without depression variables, include=FALSE}
# Create a vector of unique participant IDs
unique_participant_ids <- unique(analytic_data$id)

# Randomly sample 15 participant IDs
sampled_participant_ids <- sample(unique_participant_ids, 15)

# Create a filtered data frame with all observations for the sampled participants
sampled_analytic_data <- analytic_data |>
  filter(id %in% sampled_participant_ids) |>
  select(-date_of_birth, -age_at_injury, -status_at_followup) |>
  arrange(id, data_collection_period)

# Write the sampled data frame to a CSV file
write.csv(sampled_analytic_data, file = "~/Downloads/sampled_analytic_data.csv", row.names = FALSE)
```

## Calculate Depression Level at Year 1

Time from Study Entry to Each Observation: The time-to-event variable records the time elapsed from the study entry to each specific event or censoring time. This approach allows you to model the hazard rate as it changes over time and assess how covariates influence the risk of an event occurring at each observation point. It's well-suited for analyizing longitudinal or repeated measurements within individuals.

The following R function, `calculate_depression_level`, operationalizes depression levels at year 1 using responses to the Patient Health Questionnaire (PHQ-9) items. Initially, the function filters the dataset to focus on observations corresponding to the first follow-up interview (`data_collection_period = 1`). For each participant, the function calculates the number of PHQ-9 items scored at 1 or higher, considering these as positive symptoms of depression. The function then categorizes participants into three levels of depression severity: "No depression", "Minor depression", and "Major depression". This categorization considers both the count of positive symptoms and the presence of cardinal symptoms (anhedonia and depressed mood, represented by `phq1` and `phq2`, respectively). The resulting variable, `depression_level`, is a factor variable with labels corresponding to each depression category. This approach provides a nuanced view of depressive symptoms' presence and severity at a critical time point in the study.

The line `sum(phq1 >= 1, phq2 >= 1, phq3 >= 1, phq4 >= 1, phq5 >= 1, phq6 >= 1, phq7 >= 1, phq8 >= 1, phq9 >= 1) <= 1 | (phq1 < 1 & phq2 < 1) ~ "0",` is performing several operations: 1. **Sum of Positive Symptoms**: `sum(phq1 >= 1, phq2 >= 1, ..., phq9 >= 1)` counts the number of PHQ-9 items that have a score of 1 or higher. Each comparison (`phq# >= 1`) returns `TRUE` (counted as 1) if the item score is 1 or higher, indicating a positive symptom. 2. **Criteria for 'No Depression'**: The sum is then compared to `<= 1`. If the sum is 1 or less, it means the participant has 0 or 1 positive symptoms. 3. **Cardinal Symptoms Check**: The code `(phq1 < 1 & phq2 < 1)` checks if both cardinal symptoms are absent (both scores are less than 1). 4. **Combining Criteria with OR (`|`)**: If either the participant has 1 **or** fewer positive symptoms, or both cardinal symptoms are absent, they are categorized as "No depression".

```{r Define a Function to Calculate Depression Levels at Year 1}
#' Calculate Depression Level Based on Year 1 PHQ-9 Questionnaire Responses
#'
#' This function calculates the depression severity scores of individuals
#' at one-year post-injury using the Patient Health Questionnaire (PHQ-9) scores.
#' It evaluates cardinal symptoms and overall positive symptom count to categorize
#' depression into 'No Depression', 'Minor Depression', or 'Major Depression'.
#'
#' @param data A data frame containing the clinical research data, including item scores 
#'             for all nine items of the PHQ-9.
#' @return A data frame with added columns for positive symptom count, cardinal symptoms, 
#'         and depression level at one-year post-injury.
#' @examples
#' # Assuming `data` is a dataset containing PHQ-9 scores
#' calculate_depression_level(data)
#' @export
calculate_depression_level <- function(data) {
  data <- data |> 
    mutate(
      # Initialize new columns with default NA values
      positive_symptoms_at_year_1 = NA_real_,
      cardinal_symptoms_at_year_1 = factor(NA, levels = c("0", "1", "2", "3")),
      depression_level_at_year_1 = factor(NA, levels = c("0", "1", "2"))
    ) |>
    rowwise() |> 
    mutate(
      # all_phq_na = all(is.na(c_across(starts_with("phq")))),
      positive_symptoms_at_year_1 = if_else(data_collection_period == 1, 
                                            # sum(c_across(starts_with("phq")) >= 1, na.rm = TRUE),
                                            sum(c_across(starts_with("phq")) >= 1),
                                            NA_real_),
      cardinal_symptoms_at_year_1 = factor(if_else(data_collection_period == 1, 
                                                   case_when(
                                                     phq1 < 1 & phq2 < 1 ~ "0",  # Denied both cardinal symptoms
                                                     phq1 >= 1 & phq2 < 1 ~ "1", # Endorsed anhedonia only
                                                     phq1 < 1 & phq2 >= 1 ~ "2", # Endorsed depressed mood only
                                                     phq1 >= 1 & phq2 >= 1 ~ "3" # Endorsed both cardinal symptoms
                                                   ),
                                                   NA_character_),
                                            levels = c("0", "1", "2", "3"), 
                                            labels = c("None", "Anhedonia", "Depressed Mood", "Both")),
      depression_level_at_year_1 = factor(if_else(data_collection_period == 1, 
                                                  case_when(
                                                    positive_symptoms_at_year_1 <= 1 | (phq1 < 1 & phq2 < 1) ~ "0",   # Assign 'No Depression' label
                                                    positive_symptoms_at_year_1 <= 4 & (phq1 >= 1 | phq2 >= 1) ~ "1", # Assign 'Minor Depression' label
                                                    positive_symptoms_at_year_1 >= 5 & (phq1 >= 1 | phq2 >= 1) ~ "2"  # Assign 'Major Depression' label
                                                  ),
                                                  NA_character_),
                                          levels = c("0", "1", "2"), 
                                          labels = c("No Depression", "Minor Depression", "Major Depression"))
    ) |> 
    ungroup()
    # select(-all_phq_na)

  return(data)
}

# Calculate the Year 1 depression levels for the analytic sample
analytic_data_depression <- calculate_depression_level(analytic_data)
```

<!-- ### Create and Impute the Year 1 Problematic Substance Use and Past-Year Suicide Attempt History Variables -->

<!-- The following function is designed to process the relevant Year 1 variables from a longitudinal dataset by executing the following: -->

<!-- 1. **Input:** It takes a dataset (`data`) as its input. This dataset may contain a number of different variables, including those collected during other (i.e., non-Year 1) follow-up interviews. -->

<!-- 2. **Filtering Year 1 Data:** The function first filters this dataset to only include data from the Year 1 follow-up interview. -->

<!-- 3. **Selecting and Renaming Variables:** The function then selects specific variables that are relevant to Year 1 and renames them. This renaming helps to identify these variables in later stages of the process. -->

<!-- 4. **Joining Data:** After extracting and renaming the desired Year 1 variables, the function rejoins this subset of data back to the original dataset. This step is crucial for maintaining a complete dataset with Year 1 variables that are clearly defined. -->

<!-- 5. **Imputing Missing Values:** The function identifies the Year 1 variables that require imputation and then imputes these missing values via the "down-up" procedure within each group of the same 'id'. In other words, it fills missing values with the nearest non-missing value from the observation either below (down) or above (up) in the same 'id' group. -->

<!-- 6. **Output:** The final output of this function is the original dataset with the clearly marked Year 1 data and corresponding imputed missing values. -->

```{r Define a Function to Extract the Year 1 Variables of Interest and Impute the Values to Previous and Subsequent Observations}
#' Extract and Impute Year 1 Data
#'
#' This function processes a dataset to extract Year 1 data, rename variables, 
#' join the data back to the original dataset, and then impute missing values.
#'
#' @param data A data frame containing the dataset to be processed.
#' 
#' @return A data frame with Year 1 data extracted, renamed, and missing values imputed.
#'
#' @details 
#' The function performs several steps:
#' 1. Filters the dataset for data collection period 1.
#' 2. Selects specific variables collected at Year 1.
#' 3. Renames these variables to reflect their Year 1 timing.
#' 4. Joins the extracted Year 1 data back to the original dataset.
#' 5. Imputes missing values in Year 1 variables.
#' 
#' @examples
#' # Assuming `dataset` is the dataset to be imputed
#' result <- extract_and_impute_year_1_data(dataset)
#'
#' @export
extract_and_impute_year_1_data <- function(data) {
    # Specify the variables to extract and impute
    vars_to_extract <- c("drs_total_at_followup", 
                         "fim_total_at_followup", 
                         "gose_total_at_followup", 
                         "problematic_substance_use_at_followup", 
                         "suicide_attempt_hx_past_year_at_followup")
    year_1_vars_to_impute <- c("cardinal_symptoms_at_year_1", 
                               "positive_symptoms_at_year_1", 
                               "depression_level_at_year_1")
    
    # Extract Year 1 values and create new columns
    for (var in vars_to_extract) {
      # Replace '_followup' with '_year_1' in the variable name
      new_var_name <- sub("_followup", "_year_1", var)
      data <- data |>
        mutate(!!new_var_name := if_else(data_collection_period == 1, !!sym(var), NA))
      year_1_vars_to_impute <- c(year_1_vars_to_impute, new_var_name)
    }

    # Impute the values across all observations per participant
    imputed_data <- data |>
      group_by(id) |>
      fill(!!!syms(year_1_vars_to_impute), .direction = "downup")
    
    return(imputed_data)
}

# Extract and impute the Year 1 variables of interest for the analytic sample
analytic_data_imputed <- extract_and_impute_year_1_data(analytic_data_depression)
```

```{r Define a Function to Create a New Factor Variable to Represent Self-Reported History of Suicide Attempt}
create_suicide_attempt_hx_factor <- function(lifetime, past_year_at_injury, past_year_at_year_1) {
  # Initialize the vector for the new factor variable
  new_factor <- integer(length = length(lifetime))
  
  for(i in 1:length(lifetime)) {
    if(is.na(lifetime[i]) || is.na(past_year_at_injury[i]) || is.na(past_year_at_year_1[i])) {
      new_factor[i] <- NA # Assign NA for missing data
    } else if(lifetime[i] == "No" && past_year_at_injury[i] == "No" && past_year_at_year_1[i] == "No") {
      new_factor[i] <- 0 # Denied any history
    } else if(past_year_at_year_1[i] == "Yes") {
      new_factor[i] <- 2 # Suicide attempt in the first year post-injury
    } else if(lifetime[i] == "Yes" || past_year_at_injury[i] == "Yes") {
      new_factor[i] <- 1 # Suicide attempt history prior to injury
    } else if(lifetime[i] == "Refused" || past_year_at_injury[i] == "Refused" || past_year_at_year_1[i] == "Refused") {
      new_factor[i] <- NA # Assign NA for refused to answer
    } else {
      new_factor[i] <- NA # Catch-all for any undefined cases
    }
  }
  
  # Convert to factor with descriptive labels
  new_factor <- factor(new_factor, levels = c(0, 1, 2),
                       labels = c("Denied any history of suicide attempt",
                                  "Suicide attempt history prior to injury",
                                  "Suicide attempt in the first year post-injury"))
  
  return(new_factor)
}

# Call the function and assign the result to a new column in the data frame
analytic_data_imputed$suicide_attempt_hx = create_suicide_attempt_hx_factor(
  lifetime = analytic_data_imputed$suicide_attempt_hx_lifetime_at_injury,
  past_year_at_injury = analytic_data_imputed$suicide_attempt_hx_past_year_at_injury,
  past_year_at_year_1 = analytic_data_imputed$suicide_attempt_hx_past_year_at_year_1
)

# Remove unused factor levels from the newly created variable
analytic_data_imputed$suicide_attempt_hx <- droplevels(analytic_data_imputed$suicide_attempt_hx)
```

```{r Define a Function to Create a New Factor Variable to Represent Self-Reported History of Mental Health Treatment}
# Define a function to create a new factor variable representing full history of mental health treatment
create_mental_health_tx_factor <- function(lifetime, past_year_at_injury) {
  # Initialize the vector for the new factor variable
  new_factor <- integer(length = length(lifetime))
  
  for(i in 1:length(lifetime)) {
    if(is.na(lifetime[i]) || is.na(past_year_at_injury[i])) {
      new_factor[i] <- NA # Assign NA for missing data
    } else if(lifetime[i] == "No" && past_year_at_injury[i] == "No") {
      new_factor[i] <- 0 # Denied any history of mental health treatment
    } else if(lifetime[i] == "Yes" && past_year_at_injury[i] == "No") {
      new_factor[i] <- 1 # Mental health treatment endorsed prior to year preceding index injury only
    } else if(lifetime[i] == "Yes" && past_year_at_injury[i] == "Yes") {
      new_factor[i] <- 2 # Mental health treatment endorsed at time of injury
    } else if(lifetime[i] == "Refused" || past_year_at_injury[i] == "Refused") {
      new_factor[i] <- 5 # Participant refused to provide full mental health history
    } else {
      new_factor[i] <- 6 # Inconsistent reports of mental health history across time points
    }
  }
  
  # Convert to factor with descriptive labels
  new_factor <- factor(new_factor, levels = c(0, 1, 2, 5, 6),
                       labels = c("Denied any history of mental health treatment",
                                  "Mental health treatment received prior to year preceding index injury only",
                                  "Mental health treatment received within year preceding index injury",
                                  "Participant refused to provide full mental health history",
                                  "Inconsistent reports of mental health history across time points"))
  
  return(new_factor)
}

# Call the function and assign the result to a new column in the data frame
analytic_data_imputed$mental_health_tx_hx = create_mental_health_tx_factor(
  lifetime = analytic_data_imputed$mental_health_tx_lifetime_at_injury,
  past_year_at_injury = analytic_data_imputed$mental_health_tx_past_year_at_injury
)

# Remove unused factor levels from the newly created variable
analytic_data_imputed$mental_health_tx_hx <- droplevels(analytic_data_imputed$mental_health_tx_hx)
```

```{r Define a Function to Create a New Factor Variable to Represent Self-Reported History of Psychiatric Hospitalization}
# Define a function to create a new factor variable representing full history of psychiatric hospitalization
create_psych_hosp_hx_factor <- function(lifetime, past_year_at_injury) {
  # Initialize the vector for the new factor variable
  new_factor <- integer(length = length(lifetime))
  
  for(i in 1:length(lifetime)) {
    if(is.na(lifetime[i]) || is.na(past_year_at_injury[i])) {
      new_factor[i] <- NA # Assign NA for missing data
    } else if(lifetime[i] == "No" && past_year_at_injury[i] == "No") {
      new_factor[i] <- 0 # Denied any history of psychiatric hospitalization
    } else if(lifetime[i] == "Yes" && past_year_at_injury[i] == "No") {
      new_factor[i] <- 1 # Endorsed psychiatric hospital admission prior to year preceding index injury only
    } else if(lifetime[i] == "Yes" && past_year_at_injury[i] == "Yes") {
      new_factor[i] <- 2 # Endorsed psychiatric hospital admission within year preceding index injury
    } else if(lifetime[i] == "Refused" || past_year_at_injury[i] == "Refused") {
      new_factor[i] <- 5 # Participant refused to provide full psychiatric hospitalization history
    } else {
      new_factor[i] <- 6 # Inconsistent reports of psychiatric hospitalization history across time points
    }
  }
  
  # Convert to factor with descriptive labels
  new_factor <- factor(new_factor, levels = c(0, 1, 2, 5, 6),
                       labels = c("Denied any history of psychiatric hospitalization",
                                  "Psychiatric hospital admission prior to year preceding index injury only",
                                  "Psychiatric hospital admission within year preceding index injury",
                                  "Participant refused to provide full psychiatric hospitalization history",
                                  "Inconsistent reports of psychiatric hospitalization history across time points"))
  
  return(new_factor)
}

# Call the function and assign the result to a new column in the data frame
analytic_data_imputed$psych_hosp_hx = create_psych_hosp_hx_factor(
  lifetime = analytic_data_imputed$psych_hosp_hx_lifetime_at_injury,
  past_year_at_injury = analytic_data_imputed$psych_hosp_hx_past_year_at_injury
)

# Remove unused factor levels from the newly created variable
analytic_data_imputed$psych_hosp_hx <- droplevels(analytic_data_imputed$psych_hosp_hx)
```

```{r Convert the Units of the Time-to-Event Variables from Days to Years Select and Arrange the Columns in the Imputed Analytic Sample Data Frame}
# Convert 'time_to_event', 'time_to_censorship', and 'time_to_expiration' from days to years
analytic_data_imputed <- analytic_data_imputed |>
  mutate(
    time_to_event_in_years = time_to_event / 365.25,
    time_to_censorship_in_years = time_to_censorship / 365.25,
    time_to_expiration_in_years = time_to_expiration / 365.25,
    # Calculate age at censorship by subtracting date_of_birth from date_of_followup
    age_at_censorship = interval(start = date_of_birth, end = date_of_followup) / years(1),
    # Calculate age at death by subtracting date_of_birth from date_of_death
    age_at_expiration = interval(start = date_of_birth, end = date_of_death) / years(1)
  ) |>
  # Select and reorder data columns
  select(
    id,
    status_at_followup,
    event_status,
    data_collection_period,
    time_to_event,
    time_to_censorship,
    time_to_expiration,
    time_to_event_in_years,
    time_to_censorship_in_years,
    time_to_expiration_in_years,
    calendar_year_of_injury,
    calendar_year_of_event,
    date_of_year_1_followup,
    date_of_followup,
    date_of_death,
    date_of_birth,
    date_of_injury,
    cause_of_death_1,
    cause_of_death_2,
    cause_of_death_e,
    sex, 
    age_at_injury,
    age_at_censorship, 
    age_at_expiration,
    education_level_at_injury,
    employment_at_injury,
    marital_status_at_injury,
    cause_of_injury,
    rehab_payor_primary,
    rehab_payor_primary_type,
    drs_total_at_followup,
    fim_total_at_followup,
    gose_total_at_followup,
    drs_total_at_year_1,
    fim_total_at_year_1,
    gose_total_at_year_1,
    func_score_at_year_1,
    mental_health_tx_lifetime_at_injury,
    mental_health_tx_past_year_at_injury,
    mental_health_tx_hx,
    psych_hosp_hx_lifetime_at_injury,
    psych_hosp_hx_past_year_at_injury,
    psych_hosp_hx,
    problematic_substance_use_at_injury,
    problematic_substance_use_at_year_1,
    problematic_substance_use_at_followup,
    suicide_attempt_hx_lifetime_at_injury,
    suicide_attempt_hx_past_year_at_injury,
    suicide_attempt_hx_past_year_at_year_1,
    suicide_attempt_hx_past_year_at_followup,
    suicide_attempt_hx,
    phq1, phq2, phq3, phq4, phq5, phq6, phq7, phq8, phq9,
    positive_symptoms_at_year_1,
    cardinal_symptoms_at_year_1,
    depression_level_at_year_1
    ) |>
  arrange(id, data_collection_period)

# Save the 'analytic_data_imputed' data frame in a single .rds file
saveRDS(analytic_data_imputed, here(data_processed_dir, "analytic_data_imputed_5_year_followup.rds"))

# Save the 'analytic_data_imputed' data frame as a CSV file in the 'data/processed' subdirectory
write.csv(analytic_data_imputed, file.path(data_processed_dir, "analytic_data_imputed_5_year_followup.csv"), row.names = FALSE)
```

## Create a Sample Data Frame

```{r Create a Sample Data Frame of the Imputed Data, include=FALSE}
# Create a vector of unique participant IDs
unique_participant_ids <- unique(analytic_data_imputed$id)

# Randomly sample 15 participant IDs
sampled_participant_ids <- sample(unique_participant_ids, 15)

# Create a filtered data frame with all observations for the sampled participants
sampled_analytic_data <- analytic_data_imputed |>
  filter(id %in% sampled_participant_ids) |>
  select(-date_of_birth, -age_at_injury, -age_at_expiration, -status_at_followup) |>
  arrange(id, data_collection_period)

# Save the 'sampled_analytic_data' data frame as a CSV file in the '~/Downloads' directory
write.csv(sampled_analytic_data, file = "~/Downloads/sampled_analytic_data_5_year_followup.csv", row.names = FALSE)
```

```{r Retain Only the Last Valid Observation Per Participant}
# Retain only the last observation for each unique 'id' based on the maximum 'time_to_event' value
analytic_data_final <- analytic_data_imputed |>
  arrange(id, time_to_event) |>
  group_by(id) |>
  slice(n()) |>
  ungroup()

# Replace empty strings with NA in all columns
analytic_data_final <- apply(analytic_data_final, 2, function(x) ifelse(x == "", NA, x))

# Convert 'analytic_data_final' to a data frame
analytic_data_final <- as.data.frame(analytic_data_final)

# Function to match the class of one column to another
match_class <- function(target_col, reference_col) {
  target_class <- class(reference_col)
  
  if ("factor" %in% target_class) {
    return(as.factor(target_col))
  } else if ("numeric" %in% target_class) {
    return(as.numeric(target_col))
  } else if ("integer" %in% target_class) {
    return(as.integer(target_col))
  } else if ("character" %in% target_class) {
    return(as.character(target_col))
  } else if ("logical" %in% target_class) {
    return(as.logical(target_col))
  } else if ("Date" %in% target_class) {
    return(as.Date(target_col))
  } else {
    stop(paste("Unsupported class:", target_class))
  }
}

# Apply the function to each column
analytic_data_final <- analytic_data_final |>
  mutate(across(everything(), ~ match_class(.x, analytic_data_imputed[[cur_column()]])))

# Adjust the levels of the factor variables
analytic_data_final <- analytic_data_final |>
  mutate(
    depression_level_at_year_1 = factor(depression_level_at_year_1,
                                        levels = c("No Depression",
                                                   "Minor Depression",
                                                   "Major Depression")),
    sex = factor(sex, 
                 levels = c("Male", "Female")),
    employment_at_injury = factor(employment_at_injury, 
                                  levels = c("Competitively Employed", 
                                             "Unemployed", 
                                             "Student", 
                                             "Retired", 
                                             "Other")),
    marital_status_at_injury = factor(marital_status_at_injury,
                                      levels = c("Single",
                                                 "Married",
                                                 "Divorced",
                                                 "Other")),
    rehab_payor_primary = factor(rehab_payor_primary,
                                 levels = c("Private Insurance", "Public Insurance", "Other")),
    rehab_payor_primary_type = factor(rehab_payor_primary_type, 
                                      levels = c("Non-Medicaid", "Medicaid")),
    cause_of_injury = factor(cause_of_injury,
                             levels = c("Vehicular",
                                        "Falls",
                                        "Violence",
                                        "Other")),
    mental_health_tx_lifetime_at_injury = factor(mental_health_tx_lifetime_at_injury,
                                                 levels = c("No", "Yes")),
    mental_health_tx_past_year_at_injury = factor(mental_health_tx_past_year_at_injury,
                                                  levels = c("No", "Yes")),
    mental_health_tx_hx = factor(mental_health_tx_hx,
                                 levels = c("Denied any history of mental health treatment",
                                            "Mental health treatment received prior to year preceding index injury only",
                                            "Mental health treatment received within year preceding index injury")),
    psych_hosp_hx_lifetime_at_injury = factor(psych_hosp_hx_lifetime_at_injury,
                                              levels = c("No", "Yes")),
    psych_hosp_hx_past_year_at_injury = factor(psych_hosp_hx_past_year_at_injury,
                                               levels = c("No", "Yes")),
    psych_hosp_hx = factor(psych_hosp_hx,
                           levels = c("Denied any history of psychiatric hospitalization",
                                      "Psychiatric hospital admission prior to year preceding index injury only",
                                      "Psychiatric hospital admission within year preceding index injury")),
    problematic_substance_use_at_injury = factor(problematic_substance_use_at_injury,
                                                 levels = c("No",
                                                            "Yes")),
    problematic_substance_use_at_year_1 = factor(problematic_substance_use_at_year_1,
                                                 levels = c("No",
                                                            "Yes")),
    suicide_attempt_hx_lifetime_at_injury = factor(suicide_attempt_hx_lifetime_at_injury,
                                                   levels = c("No", "Yes")),
    suicide_attempt_hx_past_year_at_injury = factor(suicide_attempt_hx_past_year_at_injury,
                                                    levels = c("No", "Yes")),
    suicide_attempt_hx_past_year_at_year_1 = factor(suicide_attempt_hx_past_year_at_year_1,
                                                    levels = c("No", "Yes")),
    suicide_attempt_hx = factor(suicide_attempt_hx, 
                                levels = c("Denied any history of suicide attempt", 
                                           "Suicide attempt history prior to injury", 
                                           "Suicide attempt in the first year post-injury"))
  )

# Save the 'analytic_data_final' data frame in a single .rds file
saveRDS(analytic_data_final, here(data_processed_dir, "analytic_data_final_5_year_followup.rds"))

# Save the 'analytic_data_final' data frame as a CSV file in the 'data/processed' subdirectory
write.csv(analytic_data_final, file.path(data_processed_dir, "analytic_data_final_5_year_followup.csv"), row.names = FALSE)
```

```{r Create a Sample Data Frame of the Final Analytic Data, include=FALSE}
# Create a vector of unique participant IDs
unique_participant_ids <- unique(analytic_data_final$id)

# Randomly sample 15 participant IDs
sampled_participant_ids <- sample(unique_participant_ids, 15)

# Create a filtered data frame with all observations for the sampled participants
sampled_analytic_data_final <- analytic_data_final |>
  filter(id %in% sampled_participant_ids) |>
  select(-date_of_birth, -age_at_injury, -age_at_expiration, -status_at_followup) |>
  arrange(id, data_collection_period)

# Save the 'sampled_analytic_data_final' data frame to a CSV file in the '~/Downloads' directory
write.csv(sampled_analytic_data_final, file = "~/Downloads/sampled_analytic_data_final_5_year_followup.csv", row.names = FALSE)
```

```{r Create Long Format Data Frame}
# Extract the list of unique `id`s from the `analytic_data_final` data frame
id_list <- analytic_data_final$id

# Use this list of `id`s to filter `merged_data` to include all observations per `id`
analytic_data_final_long <- analytic_data_imputed |>
  filter(id %in% id_list)

# Save the 'analytic_data_final' data frame in a single .rds file
saveRDS(analytic_data_final_long, here(data_processed_dir, "analytic_data_final_long_5_year_followup.rds"))

# Save the 'analytic_data_final' data frame as a CSV file in the 'data/processed' subdirectory
write.csv(analytic_data_final_long, file.path(data_processed_dir, "analytic_data_final_long_5_year_followup.csv"), row.names = FALSE)
```

