---
title: "Survival Analysis"
author: "Brennan Hickson"
format: html
editor: visual
---

# Install and Load Libraries

```{r Initial Setup and Library Loading, echo = TRUE}
# Load the pacman package (install if necessary)
if (!requireNamespace("pacman", quietly = TRUE)) {
  install.packages("pacman")
}

# Install and load prerequisite libraries
pacman::p_load(autoReg, broom, corrplot, extrafont, forestplot, gridExtra, gt, gtsummary, here, patchwork, scales, showtext, survival, survminer, tidyverse)

# Create the 'data/processed' subdirectory if not already accessible
data_processed_dir <- here("data", "processed")
if (!dir.exists(data_processed_dir)) {
  dir.create(data_processed_dir, recursive = TRUE)
}

# Create the 'output/tables' subdirectory if not already available
tables_dir <- here("output", "tables")
if (!dir.exists(tables_dir)) {
  dir.create(tables_dir, recursive = TRUE)
}

# Create the 'output/plots/missingness' subdirectory if not already available
missingness_plots_dir <- here("output", "plots", "missingness")
if (!dir.exists(missingness_plots_dir)) {
  dir.create(missingness_plots_dir, recursive = TRUE)
}

# Create the 'output/plots/schoenfeld_residuals' subdirectory if not already available
schoenfeld_residuals_plots_dir <- here("output", "plots", "schoenfeld_residuals")
if (!dir.exists(schoenfeld_residuals_plots_dir)) {
  dir.create(schoenfeld_residuals_plots_dir, recursive = TRUE)
}

# Create the 'output/plots/martingale_residuals' subdirectory if not already available
martingale_residuals_plots_dir <- here("output", "plots", "martingale_residuals")
if (!dir.exists(martingale_residuals_plots_dir)) {
  dir.create(martingale_residuals_plots_dir, recursive = TRUE)
}

# Create the 'output/plots/multicollinearity' subdirectory if not already available
multicollinearity_plots_dir <- here("output", "plots", "multicollinearity")
if (!dir.exists(multicollinearity_plots_dir)) {
  dir.create(multicollinearity_plots_dir, recursive = TRUE)
}

# Create the 'output/plots/survival_curves' subdirectory if not already available
survival_curves_plots_dir <- here("output", "plots", "survival_curves")
if (!dir.exists(survival_curves_plots_dir)) {
  dir.create(survival_curves_plots_dir, recursive = TRUE)
}

# Load the .rds files
complete_cases_all <- readRDS(file.path(data_processed_dir, "complete_cases_all_5_year_followup.rds"))
# complete_cases_all <- readRDS(file.path(data_processed_dir, "complete_cases_all_10_year_followup.rds"))

# Import fonts from Font Book
loadfonts(device = "all", quiet = TRUE)

# Set a random seed for reproducibility
set.seed(42)
```

# Define the Covariate Groups for Nested Models

```{r Define the covariate groups for nested models}
# Define the covariate groups
all_proposed_mental_health_covariates <- c("depression_level_at_year_1",
                                           "mental_health_tx_hx",
                                           "psych_hosp_hx",
                                           "suicide_attempt_hx")

all_proposed_sociodemographic_vars <- c("calendar_year_of_injury",
                                        "age_at_injury",
                                        "sex",
                                        "education_level_at_injury", 
                                        "employment_at_injury",
                                        "marital_status_at_injury", 
                                        "rehab_payor_primary_type")

all_proposed_clinical_vars <- c("cause_of_injury", 
                                "problematic_substance_use_at_injury", 
                                "problematic_substance_use_at_year_1")

all_proposed_functional_vars <- "func_score_at_year_1"

# Define the selected covariate groups
select_depression_vars <- c("depression_level_at_year_1",
                            "mental_health_tx_hx",
                            "psych_hosp_hx",
                            "suicide_attempt_hx")

select_clinical_vars <- c("rehab_payor_primary",
                          "cause_of_injury", 
                          "problematic_substance_use_at_year_1")

select_functional_vars <- "func_score_at_year_1"

# Combine the covariate groups in the desired order
all_proposed_covariates <- c(all_proposed_mental_health_covariates,
                             all_proposed_sociodemographic_vars, 
                             all_proposed_clinical_vars,
                             all_proposed_functional_vars)
```

```{r Define the Preferred Variable Labels for the Covariates of Interest}
# Define the preferred variable labels for all covariates
var_name_mapping <- c(
  depression_level_at_year_1 = "Depression Level at Year 1",
  mental_health_tx_hx = "History of Mental Health Treatment",
  psych_hosp_hx = "History of Psychiatric Hospitalization",
  suicide_attempt_hx = "History of Suicide Attempt",
  calendar_year_of_injury = "Calendar Year of Injury",
  age_at_injury = "Age at Injury",
  sex = "Sex",
  education_level_at_injury = "Educational Attainment at Injury",
  employment_at_injury = "Employment Status at Injury",
  marital_status_at_injury = "Marital Status at Injury",
  rehab_payor_primary_type = "Medicaid Status",
  cause_of_injury = "Mechanism of Injury",
  problematic_substance_use_at_injury = "Problematic Substance Use at Injury",
  problematic_substance_use_at_year_1 = "Problematic Substance Use at Year 1",
  func_score_at_year_1 = "Function Factor Score at Year 1",
  GLOBAL = "GLOBAL"
)

# Define the preferred variable labels for all covariates and all factor levels
forest_plot_var_name_mapping <- c(
  "depression_level_at_year_1Minor Depression" = "Depression Level at Year 1: Minor Depression",
  "depression_level_at_year_1Major Depression" = "Depression Level at Year 1: Major Depression",
  "mental_health_tx_hxMental health treatment received prior to year preceding index injury only" =
    "Mental Health Treatment: Received prior to year preceding injury only",
  "mental_health_tx_hxMental health treatment received within year preceding index injury" =
    "Mental Health Treatment: Received within year preceding injury",
  "psych_hosp_hxPsychiatric hospital admission prior to year preceding index injury only" = 
    "Psychiatric Hospitalization: Admitted prior to year preceding injury only",
  "psych_hosp_hxPsychiatric hospital admission within year preceding index injury" = 
    "Psychiatric Hospitalization: Admitted within year preceding injury",
  "suicide_attempt_hxSuicide attempt history prior to injury" = "Suicide Attempt: Attempted prior to injury",
  "suicide_attempt_hxSuicide attempt in the first year post-injury" = "Suicide Attempt: Attempted in the first year post-injury",
  "calendar_year_of_injury" = "Calendar Year of Injury",
  "age_at_injury" = "Age at Injury",
  "sexFemale" = "Sex: Female",
  "education_level_at_injury" = "Education Level at Injury",
  "employment_at_injuryUnemployed" = "Employment Status at Injury: Unemployed",
  "employment_at_injuryStudent" = "Employment Status at Injury: Student",
  "employment_at_injuryRetired" = "Employment Status at Injury: Retired",
  "employment_at_injuryOther" = "Employment Status at Injury: Other",
  "marital_status_at_injuryMarried" = "Marital Status at Injury: Married",
  "marital_status_at_injuryDivorced" = "Marital Status at Injury: Divorced",
  "marital_status_at_injuryOther" = "Marital Status at Injury: Other",
  "rehab_payor_primary_typeMedicaid" = "Primary Rehabilitation Payor: Medicaid",
  "cause_of_injuryFalls" = "Mechanism of Injury: Falls",
  "cause_of_injuryViolence" = "Mechanism of Injury: Violence",
  "cause_of_injuryOther" = "Mechanism of Injury: Other",
  "problematic_substance_use_at_injuryYes" = "Problematic Substance Use at Injury: Endorsed",
  "problematic_substance_use_at_year_1Yes" = "Problematic Substance Use at Year 1: Endorsed",
  "func_score_at_year_1" = "Function Factor Score at Year 1"
)
```

# Define Aesthetic Preferences

```{r Define Themes for Customizing Plot Aesthetics}
customization <- theme(
  title = element_text(family = "Proxima Nova", face = "bold", size = 10),
  # legend.title = element_text(family = "Proxima Nova", face = "bold", size = 10),
  legend.text = element_text(family = "Proxima Nova", size = 9.5),
  axis.title.x = element_text(family = "Proxima Nova", face = "bold", size = 12, margin = margin(t = 10)),
  axis.title.y = element_text(family = "Proxima Nova", face = "bold", size = 12, margin = margin(r = 10)),
  axis.text = element_text(family = "Proxima Nova", size = 10),
  text = element_text(family = "Proxima Nova"),
  legend.position = "top"
)

customization_martingale <- theme(
  title = element_text(family = "Proxima Nova", face = "bold", size = 15),
  # legend.title = element_text(family = "Proxima Nova", face = "bold", size = 10),
  legend.text = element_text(family = "Proxima Nova", size = 10),
  axis.title.x = element_text(family = "Proxima Nova", face = "bold", size = 12, margin = margin(t = 10)),
  axis.title.y = element_text(family = "Proxima Nova", face = "bold", size = 12, margin = margin(r = 10)),
  axis.text = element_text(family = "Proxima Nova", size = 11),
  text = element_text(family = "Proxima Nova"),
  legend.position = "top"
)

# Define a theme for presenting 2-3 Schoenfeld residuals plots side-by-side
customization_trio_layout <- theme(
  title = element_text(family = "Proxima Nova", face = "bold", size = 16),
  axis.title.x = element_text(family = "Proxima Nova", face = "bold", size = 13.5, margin = margin(t = 10)),
  axis.title.y = element_text(family = "Proxima Nova", face = "bold", size = 13.5, margin = margin(r = 10)),
  axis.text = element_text(family = "Proxima Nova", size = 12),
  text = element_text(family = "Proxima Nova")
)

customization_survival_curves <- theme(
  title = element_text(family = "Proxima Nova", face = "bold", size = 10),
  # legend.title = element_text(family = "Proxima Nova", face = "bold", size = 10),
  legend.text = element_text(family = "Proxima Nova", size = 9.5),
  axis.title.x = element_text(family = "Proxima Nova", face = "bold", size = 12, margin = margin(t = 10)),
  axis.title.y = element_text(family = "Proxima Nova", face = "bold", size = 12, margin = margin(r = 10)),
  axis.text = element_text(family = "Proxima Nova", size = 10),
  text = element_text(family = "Proxima Nova"),
)

# Define custom theme settings
custom_theme <- theme_classic() + 
  customization
  # + theme(axis.text = element_text(size = 12),
  #       axis.title = element_text(size = 14.5))

custom_theme_trio_layout <- theme_classic() + 
  customization_trio_layout
```

# Define Helper Functions

```{r Define a Function to Modify, Plot, and Save Individual Schoenfeld Residual Plots for a Specified Model}
# Define a function to modify, plot, and save individual Schoenfeld residual plots for a specified model
plot_schoenfeld <- function(cox_zph_fit, model_number, var_number, var_label) {
  # Ensure 'var_number' is within the bounds of the model
  num_vars <- length(cox_zph_fit$var)
  if(var_number > num_vars) {
    stop("var_number exceeds the number of variables in the model")
  }

  # Generate the plot
  p <- ggcoxzph(cox_zph_fit,
                point.size = 2,
                point.col = "#EF5350",
                ggtheme = custom_theme)

  plot_data <- ggplot_build(p[[var_number]])
  plot_data$plot$labels$y <- var_label
  plot_gtable <- ggplot_gtable(plot_data)

  # Construct the file name and file path
  plot_name <- paste("schoenfeld_plot_for_model_", model_number, "_", var_number, ".png", sep = "")
  plot_path <- file.path(schoenfeld_residuals_plots_dir, plot_name)

  # Save the plot
  ggsave(plot_path, plot_gtable, width = 7, height = 5, dpi = 300)
}

# Define a function to modify and plot side-by-side Schoenfeld plots for a given model
plot_schoenfeld_combined_layout <- function(cox_zph_fit, var_number, var_label) {
  p <- ggcoxzph(cox_zph_fit,
                point.size = 3,
                point.col = "#EF5350",
                ggtheme = custom_theme_trio_layout)

  plot_data <- ggplot_build(p[[var_number]])
  plot_data$plot$labels$y <- var_label
  plot_gtable <- ggplot_gtable(plot_data)

  return(plot_gtable)
}
```

```{r Define a Function to Map Original Variable Names to Preferred Labels}
# Define a function to map original variable names to preferred labels
get_var_labels <- function(model, var_name_mapping) {
  # Extract the variable names from the model coefficients
  var_names <- names(coef(model))
  
  # Initialize an empty vector to store the mapped labels
  var_labels <- vector("character", length = length(var_names))
  
  # Iterate over each variable name to find and assign the corresponding label
  for (i in seq_along(var_names)) {
    var_name <- var_names[i]
    # Split the variable name on ':' and ' ' to handle interaction terms and factor levels
    split_name <- unlist(strsplit(var_name, split = ":| ", perl = TRUE))
    
    # Attempt to match each part of the split name with keys in the var_name_mapping
    label_parts <- sapply(split_name, function(part) {
      # Check if the part directly matches a key in the var_name_mapping
      if (part %in% names(var_name_mapping)) {
        return(var_name_mapping[part])
      } else {
        # If the part is a level of a factor, construct the key to find its label
        possible_keys <- grep(part, names(var_name_mapping), value = TRUE)
        if (length(possible_keys) > 0) {
          # Return the first match found
          return(var_name_mapping[possible_keys[1]])
        } else {
          # If no direct match or constructed key is found, return the part as is
          return(part)
        }
      }
    })
    
    # Combine the label parts to form the final label for the variable
    var_labels[i] <- paste(label_parts, collapse = " ")
  }
  
  # Prefix labels with "Beta(t) for" as in the original function
  var_labels <- paste("Beta(t) for", var_labels)
  
  return(var_labels)
}
```

```{r Define a Function to Create and Save the Schoenfeld Residual Plots for a Specified Model}
# Define a function to create and save the Schoenfeld residual plots for a specified model
save_schoenfeld_residuals_plots <- function(model, model_number, var_name_mapping, plot_width = 7, plot_height = 5.5) {
  # Ensure schoenfeld_residuals_plots_dir is predefined or passed as a parameter
  schoenfeld_residuals_plots_dir <- "output/plots/schoenfeld_residuals"
  
  # Get the zph fit
  cox_zph_fit <- cox.zph(model)
  
  # Get the variable labels for the model
  var_labels <- get_var_labels(model, var_name_mapping)
  
  # Ensure var_labels align with cox_zph_fit results
  if (length(var_labels) != length(cox_zph_fit$table)) {
    stop("Mismatch between number of variables and labels. Please check your name mapping and model variables.")
  }
  
  # Initialize the list to store plots
  schoenfeld_residuals_plots <- vector("list", length(var_labels))
  
  # Generate and save each plot
  for (i in seq_along(var_labels)) {
    plot_name <- paste("schoenfeld_residuals_model_", model_number, "_var_", i, ".png", sep = "")
    plot_path <- file.path(schoenfeld_residuals_plots_dir, plot_name)
    
    # Check for valid index before plotting
    if (i <= length(cox_zph_fit$table)) {
      schoenfeld_residuals_plots[[i]] <- plot_schoenfeld_combined_layout(cox_zph_fit, i, var_labels[i])
      ggsave(plot_path, schoenfeld_residuals_plots[[i]], width = plot_width, height = plot_height, dpi = 300)
    } else {
      warning(paste("Skipping index", i, "- out of bounds for cox_zph_fit$table."))
    }
  }
  
  return(schoenfeld_residuals_plots)
}
```

```{r Define a Function to Combine and Save Grouped Schoenfeld Residual Plots}
# Define a function to combine and save grouped plots
save_combined_plots <- function(plots, start_index, end_index, ncol, file_name) {
  combined_plot <- do.call(grid.arrange, c(plots[start_index:end_index], ncol = ncol))
  file_path <- file.path(schoenfeld_residuals_plots_dir, file_name) # Assuming schoenfeld_residuals_plots_dir is defined
  ggsave(file_path, plot = combined_plot, width = 21, height = 5.5)
}
```

# Cox Proportional Hazards Regression

The `coxph` function from the `survival` package is used to fit the Cox proportional hazards regression model. The basic syntax is `coxph(Surv(time, event) ~ covariates, data = dataset)`, where:

-   **`Surv(time, event)`** is a `Surv` object, where `time` represents the time to either the event or censorship, and `event` is a binary variable indicating whether the event (e.g., death) occurred (1) or was censored (0).
-   **`covariates`** is a formula that specifies the covariates (i.e., predictor variables) to be included in the model.
-   **`data`** specifies the dataset that contains the covariates of interest.

## Univariate Cox Regression Modeling

Univariate Cox regression modeling is a statistical technique used in survival analysis to assess the relationship between the survival time of participants and a single predictor variable. The primary purpose of univariate Cox regression is to determine whether a single variable is associated with the hazard of an event (e.g., death, recurrence of disease) without controlling for the effects of other variables.

Univariate models might need to be examined for the following reasons:

1.  **Identification of Significant Predictors:** Univariate Cox regression helps to identify potential predictors that may have a significant impact on survival outcomes. By examining each predictor individually, researchers can identify which variables warrant further investigation in multivariable models.
2.  **Screening Variables:** Univariate analysis can be used to screen a large number of potential predictors efficiently. Variables that demonstrate significant associations with survival outcomes in univariate analysis can be prioritized for inclusion in multivariable models.
3.  **Understanding Variable Effects:** Univariate Cox regression allows researchers to understand the direction and magnitude of the effect of each predictor on survival outcomes in isolation from other variables.

Performing univariate Cox regression in R can be accomplished using the `coxph()` function from the `survival` package. The `univariate_cox_models` function below fits the univariate Cox regression model for each variable specified in a list of variables and prints the summary of each univariate model (with results rounded to two digits) by calling the `round_cox_summary` function.

```{r Define a Helper Function to Round and Format the Cox Proportional Hazards Summary Results}
# Define a helper function to round and format the Cox model summary
#' Provide Rounded Summary of Cox Regression Model
#'
#' This function rounds the numeric values in the summary of a Cox regression model to two decimal places.
#'
#' @param cox_model A fitted Cox regression model object.
#' @return A rounded summary of the Cox regression model.
#' @export
#' @examples
#' # Example usage:
#' # round_cox_summary(my_cox_model)
round_cox_summary <- function(cox_model) {
  # Get the summary of the Cox model
  summary_cox <- summary(cox_model)
  
  # Round the numeric values in the summary to 2 decimal places
  summary_cox$coefficients <- round(summary_cox$coefficients, 2)
  if (!is.null(summary_cox$conf.int)) {
    summary_cox$conf.int <- round(summary_cox$conf.int, 2)
  }
  summary_cox$logtest <- round(summary_cox$logtest, 2)
  summary_cox$waldtest <- round(summary_cox$waldtest, 2)
  summary_cox$sctest <- round(summary_cox$sctest, 2)
  if (!is.null(summary_cox$rsq)) {
    summary_cox$rsq <- round(summary_cox$rsq, 2)
  }
  
  # Return the modified summary
  return(summary_cox)
}
```

```{r Define a Function to Generate and Summarize the Univariate Cox Proportional Hazards Summary Results for Each Covariate in the Grouped Covariate Sets}
#' Perform Univariate Cox Regression Modeling
#'
#' This function performs univariate Cox regression modeling for each variable specified in the \code{variables} argument. It prints the summary of each model and saves the rounded summary to the R environment with variable-specific names.
#'
#' @param variables A character vector containing the names of the predictor variables.
#' @param data A data frame containing the variables of interest.
#' @return None (results are printed to the console and saved to the R environment).
#' @export
#' @examples
#' # Example usage:
#' # univariate_cox_models(c("covariate1", "covariate2"), my_data)
univariate_cox_models <- function(variables, data) {
  for (var in variables) {
    # Print the variable being processed for debugging
    cat("Processing variable:", var, "\n")
    
    # Check if the required columns are present in the data
    if (!all(c("time_to_event_in_years", "event_status") %in% colnames(data))) {
      stop("Data does not contain required columns: 'time_to_event_in_years' and 'event_status'")
    }
    
    # Check if the data columns are of the correct type
    if (!is.numeric(data$time_to_event_in_years)) {
      stop("The 'time_to_event_in_years' column must be numeric")
    }
    if (!is.numeric(data$event_status)) {
      stop("The 'event_status' column must be numeric")
    }
    
    # Print the formula being used for debugging
    formula_str <- paste('Surv(time_to_event_in_years, event_status) ~', var)
    cat("Using formula:", formula_str, "\n")
    
    # Construct the Cox regression model using each covariate
    cox_model <- tryCatch(
      {
        coxph(as.formula(formula_str), data = data)
      },
      error = function(e) {
        cat("Error in Cox model for variable", var, ":", e$message, "\n")
        return(NULL)
      }
    )
    
    # Check if the model was successfully created
    if (is.null(cox_model)) {
      next
    }
    
    # Print the summary for variable
    cat("Summary for variable:", var, "\n")
    
    # Print the rounded summary of the model
    rounded_summary <- round_cox_summary(cox_model)
    print(rounded_summary)
    
    # Save the rounded summary to the R environment
    assign(paste0("rounded_summary_", var), rounded_summary, envir = .GlobalEnv)
  }
}
```

```{r Fit the Univariate Models and Print Results Summaries}
univariate_cox_models(all_proposed_mental_health_covariates, complete_cases_all)
univariate_cox_models(all_proposed_sociodemographic_vars, complete_cases_all)
univariate_cox_models(all_proposed_clinical_vars, complete_cases_all)
univariate_cox_models(all_proposed_functional_vars, complete_cases_all)
```

## Multivariable Cox Regression Modeling

Multivariable Cox regression modeling is used to assess the simultaneous effect of multiple predictor variables on survival outcomes while adjusting for the effects of other variables. The primary purpose of multivariable Cox regression is to identify dependent predictors of survival and to quantify their associations with survival outcomes while accounting for potential confounding variables.

Multivariable models may need to be examined to:

1.  **Account for Confounding Variables:** Multivariable Cox regression allows researchers to control for the effects of potential confounding variables that may influence both the predictor variables and the outcome. By adjusting for confounding variables, researchers can obtain more accurate estimates of the associations between predictor variables and survival outcomes.
2.  **Understand Joint Effects:** Multivariable Cox regression enables the examination of the joint effects of multiple predictor variables on survival outcomes. It helps identify combinations of predictors that have a significant impact on survival beyond their individual effects.
3.  **Improve Prediction Accuracy:** By incorporating multiple predictor variables into the model, multivariable Cox regression may improve the accuracy of survival predictions compared to univariate models, particularly when multiple predictors interact with each other.

Nested multivariable Cox regression models are used to compare the fit of nested models, where one model is a subset of another. This comparison helps determine whether the inclusion of additional variables significantly improves the model's fit and predictive ability.

Like univariate Cox regression, multivariable Cox regression in R can be performed using the `coxph()` function from the `survival` package, as shown in the example below:

```{r Example Multivariable Cox Regression Model, eval = FALSE}
# # Fit multivariable Cox regression model
# cox_model <- coxph(Surv(time, status) ~ covariate1 + covariate2 + covariate3, data = dataset)
# 
# # Display summary of the multivariable Cox model
# summary(cox_model)
```

In the code chunk above, `time`, `status`, `covariate1`, `covariate2`, etc., should be replaced with the actual names of the desired variables, and `dataset` should be replaced with the name of the dataset in which these variables are contained. The `Surv()` function creates a survival object, and `coxph()` fits the Cox proportional hazards model with multiple predictor variables.

In our case, `time` is represented by the `time_to_event_in_years` variable (which represents the time to either death or censorship in years), and `status` is represented by the `event_status` variable (which is coded as 0 for censored participants and 1 for decedents). These variables are present in the `complete_cases_all` dataset, which contains data for the set of participants who possessed complete data for all covariates of interest.

To fit the nested models, we'll apply the `Surv(time, status) ~ covariate1 + covariate2 + covariate3...` formula incrementally to previously fitted models. In other words, Model 2 will contain the Model 1 covariate (i.e., depression_level_at_year_1) and all other mental health-related covariates; Model 3 will contain all Model 2 covariates plus the sociodemographic variables; Model 4 will contain all Model 3 covariates plus the clinical variables; and Model 5 will contain all Model 4 covariates plus the function factor score variable.

```{r Models 1-5: Fit the Multivariable Models for All Proposed Covariates}
# Fit Model 1: Depression Level at Year 1
model_1 <- coxph(Surv(time_to_event_in_years, event_status) ~ depression_level_at_year_1, complete_cases_all)

# Fit Model 2: Mental Health-Related Covariates
model_2_formula <- as.formula(paste('Surv(time_to_event_in_years, event_status) ~', 
                                    paste(all_proposed_mental_health_covariates, collapse = " + ")))
model_2 <- coxph(model_2_formula, data = complete_cases_all)

# Fit Model 3: Mental Health + Sociodemographic covariates
model_3_formula <- as.formula(paste('Surv(time_to_event_in_years, event_status) ~', 
                                    paste(c(all_proposed_mental_health_covariates, all_proposed_sociodemographic_vars), 
                                          collapse = " + ")))
model_3 <- coxph(model_3_formula, data = complete_cases_all)

# Fit Model 4: Mental Health + Sociodemographic + Clinical covariates
model_4_formula <- as.formula(paste('Surv(time_to_event_in_years, event_status) ~', 
                                    paste(c(all_proposed_mental_health_covariates, all_proposed_sociodemographic_vars,
                                            all_proposed_clinical_vars), 
                                          collapse = " + ")))
model_4 <- coxph(model_4_formula, data = complete_cases_all)

# Fit Model 5: Mental Health + Sociodemographic + Clinical + Functional covariates
model_5_formula <- as.formula(paste('Surv(time_to_event_in_years, event_status) ~', 
                                    paste(c(all_proposed_mental_health_covariates, all_proposed_sociodemographic_vars,
                                            all_proposed_clinical_vars, all_proposed_functional_vars), 
                                          collapse = " + ")))
model_5 <- coxph(model_5_formula, data = complete_cases_all)

# # Fit Model 6: Mental Health + Sociodemographic + Clinical + Functional covariates with the interaction term
# model_6_formula <- update(model_5_formula, . ~ . + age : depression_level_at_year_1)
# 
# # Fit Model 6
# model_6 <- coxph(model_6_formula, data = complete_cases_all)
```

```{r Summarize the Multivariable Models and Round the Results to Two Decimal Places}
# Summarize the models and round results to two decimal places
rounded_summary_model_2 <- round_cox_summary(model_2)
rounded_summary_model_3 <- round_cox_summary(model_3)
rounded_summary_model_4 <- round_cox_summary(model_4)
rounded_summary_model_5 <- round_cox_summary(model_5)
# rounded_summary_model_6 <- round_cox_summary(model_6)

# Print the rounded summaries
print(rounded_summary_model_2)
print(rounded_summary_model_3)
print(rounded_summary_model_4)
print(rounded_summary_model_5)
# print(rounded_summary_model_6)
```

```{r Display and Save Multivariable Cox Proportional Hazards Model Results in a Nested Summary Table}
# Create gtsummary Tables with modified variable labels
tbl_model_1 <- tbl_regression(model_1, exponentiate = TRUE, label = var_name_mapping, pvalue_fun = purrr::partial(style_pvalue, digits = 2)) |>
  # modify_header(label ~ "**Model 1: Depression Level at Year 1**") |>
  modify_header(p.value ~ "**_p_**") |>
  bold_labels() |>
  bold_p()

tbl_model_2 <- tbl_regression(model_2, exponentiate = TRUE, label = var_name_mapping, pvalue_fun = purrr::partial(style_pvalue, digits = 2)) |>
  # modify_header(label ~ "**Model 2: Mental Health**") |>
  modify_header(p.value ~ "**_p_**") |>
  bold_labels() |>
  bold_p()

tbl_model_3 <- tbl_regression(model_3, exponentiate = TRUE, label = var_name_mapping, pvalue_fun = purrr::partial(style_pvalue, digits = 2)) |>
  # modify_header(label ~ "**Model 3: Mental Health + Sociodemographic**") |>
  modify_header(p.value ~ "**_p_**") |>
  bold_labels() |>
  bold_p()

tbl_model_4 <- tbl_regression(model_4, exponentiate = TRUE, label = var_name_mapping, pvalue_fun = purrr::partial(style_pvalue, digits = 2)) |>
  # modify_header(label ~ "**Model 4: Mental Health + Sociodemographic + Clinical**") |>
  modify_header(p.value ~ "**_p_**") |>
  bold_labels() |>
  bold_p()

tbl_model_5 <- tbl_regression(model_5, exponentiate = TRUE, label = var_name_mapping, pvalue_fun = purrr::partial(style_pvalue, digits = 2)) |>
  # modify_header(label ~ "**Model 5: Mental Health + Sociodemographic + Clinical + Functional**") |>
  modify_header(p.value ~ "**_p_**") |>
  bold_labels() |>
  bold_p()

# Merge the tables
tbl_nested_models <- tbl_merge(
  tbls = list(tbl_model_1, tbl_model_2, tbl_model_3, tbl_model_4, tbl_model_5),
  tab_spanner = c("**Model 1**", "**Model 2**", "**Model 3**", "**Model 4**", "**Model 5**")
)

# Convert the merged table and adjust the font size
tbl_nested_models <- tbl_nested_models |>
  as_gt() |>
  gt::tab_options(table.font.size = 'small')

# Save the table
gtsave(tbl_nested_models, here(tables_dir, "table_2_nested_cox_regression_models.png"))
```

```{r Display and Save Cox Proportional Hazards Model Results in Separate Summary Tables}
# Function to create and customize the gtsummary table
create_summary_table <- function(model, var_name_mapping) {
  tbl <- tbl_regression(model, exponentiate = TRUE) %>%
    modify_header(label ~ "**Characteristic**") %>%  # Bold the header
    bold_labels() %>%                             # Bold the variable names
    modify_fmt_fun(p.value ~ function(x) ifelse(x < 0.05, paste0("<b>", formatC(x, format = "f", digits = 3), "</b>"), formatC(x, format = "f", digits = 3))) # Format p-values

  for (old_name in names(var_name_mapping)) {
    new_name <- var_name_mapping[[old_name]]
    tbl <- tbl %>%
      modify_table_body(
        ~ .x %>% mutate(label = ifelse(label == old_name, new_name, label))
      )
  }
  return(tbl)
}

# Summarize the models using tbl_regression from gtsummary and apply custom variable labels
summary_model_1 <- create_summary_table(model_1, var_name_mapping)
summary_model_2 <- create_summary_table(model_2, var_name_mapping)
summary_model_3 <- create_summary_table(model_3, var_name_mapping)
summary_model_4 <- create_summary_table(model_4, var_name_mapping)
summary_model_5 <- create_summary_table(model_5, var_name_mapping)

# Modify and print the tables with gt
gt_summary_model_1 <- summary_model_1 |>
  as_gt() |>
  gt::tab_options(table.font.size = 'small')

gt_summary_model_2 <- summary_model_2 |> 
  as_gt() |> 
  gt::tab_options(table.font.size = 'small')

gt_summary_model_3 <- summary_model_3 |> 
  as_gt() |> 
  gt::tab_options(table.font.size = 'small')

gt_summary_model_4 <- summary_model_4 |> 
  as_gt() |> 
  gt::tab_options(table.font.size = 'small')

gt_summary_model_5 <- summary_model_5 |> 
  as_gt() |> 
  gt::tab_options(table.font.size = 'small')

# Print the summaries
print(gt_summary_model_1)
print(gt_summary_model_2)
print(gt_summary_model_3)
print(gt_summary_model_4)
print(gt_summary_model_5)

# Save the Cox proportional hazards models as R objects
saveRDS(model_1, here(data_processed_dir, "cox_model_1_5_year_followup.rds"))
saveRDS(model_2, here(data_processed_dir, "cox_model_2_5_year_followup.rds"))
saveRDS(model_3, here(data_processed_dir, "cox_model_3_5_year_followup.rds"))
saveRDS(model_4, here(data_processed_dir, "cox_model_4_5_year_followup.rds"))
saveRDS(model_5, here(data_processed_dir, "cox_model_5_5_year_followup.rds"))
# saveRDS(model_6, here(data_processed_dir, "cox_model_6_5_year_followup.rds"))
```

### Assess Multicollinearity

Multicollinearity occurs when two or more predictor variables in a regression model are highly correlated, indicating that one predictor variable can be linearly predicted from the others with a substantial degree of accuracy. While multicollinearity does not reduce the predictive power or reliability of the model as a whole, it affects the individual preictor variables, making it difficult to assess their independent effects on the outcome variable. Ultimately, this can lead to difficulties in estimating the model parameters accurately. Additionally, high multicollinearity can inflate the variance of the coefficient estimates and make the model unstable, which may lead to overfitting and unreliable predictions. The `vif` function from the `car` package provides a quantitative measure to assess the severity of multicollinearity.

-   **Coefficient Estimation and Interpretation:** In Cox regression mdoels, which are used to analyze and interpret the times until an event of interest occurs, multicollinearity can make it challenging to discern the effect of each independent variable on the hazard rate (the dependent variable in Cox models). When predictors are highly correlated, the coefficients of these variables may become unstable, meaning small changes in the data can lead to large changes in the coefficient estimates. This instability can complicate the interpretation of the model's results, as it becomes unclear which variables are genuinely influencing the outcome.

-   **Statistical Significance:** Multicollinearity can inflate the standard errors of the coefficient estimates. Higher standard errors can lead to wider confidence intervals and make it harder to detect a statistically significant effect, even if it truly exists. Assessing multicollinearity allows researchers to understand whether the lack of statistical significance is due to the predictor variables being too closely related to each other rather than their lack of an association with the outcome.

-   **Model Specification:** Identifying multicollinearity can indicate problems with the model specification, including redundant variables. In the context of Cox regression, where the goal is often to understand the impact of specific variables on the time to an event, recognizing and addressing multicollinearity is crucial for developing a parsimonious model that accurately represents the underlying phenomenon.

-   **Variable Selection:** In applied research, Cox regression models are frequently used for variable selection or to identify risk factors associated with time-to-event data. Multicollinearity can obscure which variables are truly important. By assessing multicollinearity, researchers can make more informed decisions about which variables to include in the model, potentially using methods like stepwise selection, penalized regression, or principal component analysis to mitigate the effects of multicollinearity.

-   **Generalizability:** Models afflicted with multicollinearity may not generalize well to other datasets, as the relationships among variables that are specific to the particular sample used for model fitting may not exist in other samples. Assessing and addressing multicollinearity can help ensure that the conclusions drawn from a Cox regression model are more widely applicable.

In summary, assessing multicollinearity within the context of Cox regression is crucial for ensuring the reliability, interpretability, and generalizability of the model's findings. It helps in making more accurate inferences about the relationships between predictor variables and the time until an event occurs, which is essential in fields like medical research, survival analysis, and time-to-event studies.

#### Plot Multicollinearity

-   Collinearity in a Cox regression leads to the same problems as it does in other forms of regression (unstable parameter estimates, difficulty in interpretation), and the solutions to the problem are the same (e.g., remove redundant variables). However, unlike `lm` and `glm`, the `car::vif()` function will not work with a `coxph` object. Instead, first fit a linear regression model with any numeric variable as the outcome (here we use the event time variable), and compute the VIFs for that model.

**Assess Multicollinearity Using VIF:** The `vif` function from the `car` package does not directly accept Cox regression models. Thus, you will need to fit a linear model (or a similar model) using the same covariates to assess multicollinearity. The idea here is not to interpret this linear model but to use it for assessing multicollinearity among covariates.

```{r Assess Multicollinearity via the Variance Inflation Factor}
# Define the VIF model using all proposed covariates
model_5_vif <- lm(as.formula(paste("event_status ~", paste(all_proposed_covariates, collapse = " + "))), 
                  data = complete_cases_all)

# Create a gtsummary table for the model
vif_table <- tbl_regression(model_5_vif, label = var_name_mapping, pvalue_fun = purrr::partial(style_pvalue, digits = 2)) |>
  modify_header(label ~ "**VIF Summary Table**", p.value ~ "**_p_**") |>
  bold_labels() |>
  bold_p() |>
  add_vif() |>
  as_gt()

# Define the file path using here() and save the gt table as a PNG file
gtsave(vif_table, here(tables_dir, "table_3_vif_summary_table.png"))

# Display the table in the console
vif_values <- car::vif(model_5_vif)
print(vif_values)
```

```{r Assess Multicollinearity via the Correlation Matrix}
predictors <- complete_cases_all |>
  select(-id, -event_status, -time_to_event_in_years, -rehab_payor_primary,
         -drs_total_at_year_1, -fim_total_at_year_1, -gose_total_at_year_1,
         -mental_health_tx_lifetime_at_injury, -mental_health_tx_past_year_at_injury,
         -psych_hosp_hx_lifetime_at_injury, -psych_hosp_hx_past_year_at_injury,
         -suicide_attempt_hx_lifetime_at_injury, -suicide_attempt_hx_past_year_at_injury,
         -suicide_attempt_hx_past_year_at_year_1)  # Exclude the survival object variables and non-model covariates

# Select only numeric columns
numeric_predictors <- predictors |>
  select(where(is.numeric))

# Calculate the correlation matrix
correlation_matrix <- cor(numeric_predictors, use = "complete.obs")
print(correlation_matrix)

# Rename the correlation matrix variable names
colnames(correlation_matrix) <- var_name_mapping[colnames(correlation_matrix)]
rownames(correlation_matrix) <- var_name_mapping[rownames(correlation_matrix)]

# Generate a color palette for the correlation matrix
col <- colorRampPalette(c("#BB4444", "#EE9988", "#FFFFFF", "#77AADD", "#4477AA"))

# Define the file path for saving the plot
plot_file_path <- file.path(multicollinearity_plots_dir, "correlation_matrix.png")

# Save the correlation matrix plot to a file
png(filename = plot_file_path, width = 4000, height = 3000, res = 300)  # 300 DPI for high resolution
par(family = "Proxima Nova")
# Visualize the correlation matrix
corrplot(correlation_matrix, method = "shade", shade.col = NA, tl.col = "black", tl.srt = 45,
         col = col(200), addCoef.col = "black", cl.pos = "n", order = "AOE")
dev.off()
```

**Interpretation of VIF Values:**

The output provides two main pieces of information for each predictor: the Generalized VIF (GVIF) and its adjusted version, `GVIF^(1/(2*df))`. The adjustment is made for predictors that are categorical with degrees of freedom (Df) greater than 1, to make the GVIF comparable across predictors with different numbers of categories. The VIF values can be interpreted as follows:

- *GVIF:** This is the raw VIF value before adjusting for the degrees of freedom of the predictor. A higher GVIF value indicates more multicollinearity.
- **GVIF^(1/*2*Df)):** This is the adjusted VIF value, which is more commonly interpreted. It accounts for the degrees of freedom of each predictor, making it easier to compare across predictors with different numbers of categories (Df).

The rule of thumb for VIF values is as follows:

- A VIF of 1 indicates no correlation among the kth predictor and the remaining predictor variables.

- VIF values between 1 and 5 suggest moderate correlation, but they are often not a cause for concern.

- VIF values greater than 5 or 10 are typically considered indicative of problematic multicollinearity, requiring further investigation or action, such as removing variables, combining variables, or applying regularization techniques.

In our case:

- Most variables have VIF values well below 5, suggesting that they do not have severe multicollinearity issues. 

- The variable `age` has a VIF of approximately 1.786, which is higher than others but still below the threshold of 5 or 10, indicating moderate but not severe multicollinearity. 

- Other variables, including those with multiple categories (indicated by Df > 1), also have adjusted VIF values that do not indicate severe multicollinearity, with values all below the threshold commonly used to suggest significant concerns. 

Based on the provided VIF values, there does not appear to be significant multicollinearity issues among the predictors in Model 5. The highest VIF value is around 1.786 for `age`, which is within acceptable limits, although it is the highest among the variables listed.

# Assumptions of Cox Regression

In order to properly implement a Cox proportional hazards model and interpret its results accurately, several assumptions must be fulfilled. These assumptions include:

### 1. Proportional Hazards Assumption:
The most fundamental assumption of the Cox proportional hazards model states that the ratio of the hazard rates (i.e., the risk of the event occurring at a given time point) between any two individuals is constant over time. Simply put, if one individual has twice the risk of an event occurring at the beginning of the study, the same individual should have twice the risk at any later time point, assuming other factors remain constant. Violating this assumption can lead to incorrect conclusions about how covariates affect the hazard rate over time.

-   This assumption can be assessed using graphical methods (such as plotting Schoenfeld residuals against time) or statistical tests (such as the Schoenfeld or Grambsch test).

### 2. Independence:
The observations must be independent of one another. In other words, the occurrence of an event for one participant should not influence the occurrence of events for other participants.

-   This assumption is typically ensured through proper study design, such as random sampling or appropriate statistical techniques for handling clustered or correlated data.

### 3. Linearity in the Log-Hazard:
For continuous covariates, this assumption states that a unit change in the covariate has a constant effect on the log-hazard. It implies that the relationship between continuous covariates and the log-hazard is linear. Non-linearity can lead to misinterpretation of how changes in covariates affect the hazard rate.

-   This assumption can be checked visually using plots (such as partial residual plots) or through statistical tests.

### 4. No Perfect Multicollinearity:
There should be no perfect linear relationships among the independent variables. This means that one independent variable should not be a perfect predictor of another. Multicollinearity can be assessed using techniques like variance inflation factor (VIF).

## Assessing Model Assumptions

### 1. Proportional Hazards Assumption:

The proportional hazards assumption is a fundamental concept underpinning the Cox proportional hazards (PH) regression model. This assumption posits that the hazard ratios (HRs) between two individuals or groups are constant over time. In other words, if one individual is twice as likely to experience the event of interest (e.g., death, failure, relapse) at the beginning of the study, this relative risk remains constant throughout the study period. This does not mean the risks themselves are constant over time, but rather that the risks between groups change in a proportional manner.

The Cox PH model is expressed as:
$$
h(t, X) = h_0(t) \exp(\beta_1 X_1 + \beta_2 X_2 + ... + \beta_p X_p)
$$
- $h(t,X)$ is the hazard at time $t$ for an individual with a set of covariates $X$.
- $h_0(t)$ is the baseline hazard function, representing the hazard for an individual with all covariates equal to zero.
- The $\beta$ coefficients represent the effect of each covariate on the hazard.

The assumption of proportional hazards implies that the function $\exp(\beta_1 X_1 + \beta_2 X_2 + ... + \beta_p X_p)$ is multiplicative with respect to the hazard and does not depend on time $t$. That is, the effect of a one-unit change in $X_i$ on the hazard is multiplicative and constant over time.

Several methods can be used to check whether the proportional hazards assumption holds:

1. Graphical Checks
- **Log-Log Survival Curves:** Plotting the log-minus-log of the survival function against log(time) for each group defined by the covariates. If the proportional hazards assumption holds, these curves should be approximately parallel. 
- **Cumulative Hazard Plots:** Similarly, plotting cumulative hazard functions for groups can provide insights, where parallel lines suggest proportionality.

2. Schoenfeld Residuals
- **Schoenfeld Residuals Test:** The most widely used method for testing the proportional hazards assumption includes the Schoenfeld residuals test. Schoenfeld residuals are time-dependent residuals. If the PH assumption holds, there should be no trend in the residuals over time. Plotting Schoenfeld residuals against time and checking for any systematic pattern can help assess the assumption. Statistical tests (e.g., correlation test between residuals and time) can quantify this assessment.
- **Global Test:** A statistical test for the overall model's adherence to the proportional hazards assumption can be performed using the Schoenfeld residuals.

3. Time-Dependent Covariates:
- **Adding Interaction with Time:** By incorporating interactions between covariates and a function of time (e.g., $X_i \times \log(t)$) in the Cox model, one can test if the hazard ratios change over time. A significant interaction indicates a violation of the proportional hazards assumption.

4. Stratification
- **Stratified Cox Model:** Although not a method to test the PH assumption, using a stratified Cox model can be a way to handle violations of this assumption. Stratification allows the baseline hazard function, $h_0(t)$, to vary across groups of a non-proportional covariate, while assuming proportional hazards within each stratum.

The reason that Cox regression is called Cox "proportional hazards" (PH) regression is that the standard form of the model assumes the hazards for any two individuals have the same proportion at all times. Thus, the PH assumption implies the HR measuring the effect of any predictor is constant over time.

-   **Schoenfeld Residuals Test:** This is a formal statistical test to check the proportional hazards assumption. If the p-value is low (typically \<0.05), it suggests that the proportional hazards assumption may be violated.
-   **Graphical Checks:** Plotting the Schoenfeld residuals against time can give a visual indication of whether this assumption holds. If the residuals display a random scatter around zero without any systematic pattern, the assumption is likely met.

The global Schoenfeld test is a statistical procedure used to assess the proportional hazards assumption in the context of Cox PH regression models. The purpose of the global Schoenfeld test is to evaluate whether the proportional hazards assumption holds for the model as a whole, rather than testing each covariate individually. This is crucial because the assumption's validity affects the model's interpretability and the accuracy of its predictions.

The global Schoenfeld test is based on Schoenfeld residuals, which are time-varying residuals that provide a way to examine how the relationship between the covariates and the hazard changes over time. If the proportional hazards assumption is true, there should be no systematic pattern (i.e., trend) in the Schoenfeld residuals over time for any of the covariates in the model.

The steps involved in conducting a global Schoenfeld test are generally as follows:

1. **Calculate Schoenfeld Residuals:** For each event time, Schoenfeld residuals are calculated, reflecting the difference between the observed covariate values and the expected values under the proportional hazards assumption. 
2. **Assess Trends Over Time:** The test evaluates whether there is a significant trend in the Schoenfeld residuals over time. This is typically done by correlating these residuals with time or by using a more sophisticated test that accounts for the specific distribution of event times.
3. **Global Test Statistic:** A global test statistic is computed to assess the overall evidence against the proportional hazards assumption across all covariates. This involves aggregating the evidence from individual covariates into a single test statistic, often using a chi-squared test.

#### Interpretation
- **If the test indicates non-significance,** it suggests that there is no strong evidence against the proportional hazards assumption, and the model may be considered appropriate under this assumption.
- **If the test is significant,** it suggests that the proportional hazards assumption may not hold for one or more covariates in the model, indicating the need for further investigation or model adjustment. This could involve examining individual covariates more closely, incorporating time-varying covariates, or using alternative modeling approaches that do not rely on the proportional hazards assumption.

```{r Test the Proportional Hazards Assumption for the Cox Regression Model Fit of All Proposed Covariates Using the Schoenfeld Residuals Test}
# Perform the Schoenfeld test on Models 2-5
schoenfeld_test_results_model_1 <- cox.zph(model_1)
schoenfeld_test_results_model_2 <- cox.zph(model_2)
schoenfeld_test_results_model_3 <- cox.zph(model_3)
schoenfeld_test_results_model_4 <- cox.zph(model_4)
schoenfeld_test_results_model_5 <- cox.zph(model_5)


# Function to extract results into a data frame
extract_schoenfeld_results <- function(test_result) {
  data.frame(
    Variable = rownames(test_result$table),
    chisq = test_result$table[, "chisq"],
    df = test_result$table[, "df"],
    p = test_result$table[, "p"]
  )
}

# Extract results for each model and replace "NA" with "GLOBAL"
schoenfeld_results_model_1 <- extract_schoenfeld_results(schoenfeld_test_results_model_1)
schoenfeld_results_model_2 <- extract_schoenfeld_results(schoenfeld_test_results_model_2)
schoenfeld_results_model_3 <- extract_schoenfeld_results(schoenfeld_test_results_model_3)
schoenfeld_results_model_4 <- extract_schoenfeld_results(schoenfeld_test_results_model_4)
schoenfeld_results_model_5 <- extract_schoenfeld_results(schoenfeld_test_results_model_5)

# Function to create a gt table for the results with variable renaming
create_gt_table <- function(results_df, model_name, var_name_mapping) {
  results_df <- results_df |>
    mutate(Variable = var_name_mapping[Variable])
  
  results_df |>
    gt() |>
    tab_header(
      title = paste("Schoenfeld Residuals Test Results for", model_name)
    ) |>
    fmt_number(
      columns = c(chisq, df, p),
      decimals = 3
    ) |>
    cols_label(
      Variable = "Characteristic",
      chisq = "Chi-Square",
      df = "Degrees of Freedom",
      p = "p-value"
    ) |>
    tab_style(
      style = cell_text(weight = "bold"),
      locations = cells_column_labels(everything())
    ) |>
    tab_style(
      style = cell_text(weight = "bold"),
      locations = cells_body(
        columns = "p",
        rows = p < 0.05
      )
    ) |>
    tab_footnote(
      footnote = "p-values less than 0.05 indicate violation of the proportional hazards assumption",
      locations = cells_column_labels("p")
    )
}

# Create gt tables for each model with variable renaming
gt_table_model_1 <- create_gt_table(schoenfeld_results_model_1, "Model 1", var_name_mapping)
gt_table_model_2 <- create_gt_table(schoenfeld_results_model_2, "Model 2", var_name_mapping)
gt_table_model_3 <- create_gt_table(schoenfeld_results_model_3, "Model 3", var_name_mapping)
gt_table_model_4 <- create_gt_table(schoenfeld_results_model_4, "Model 4", var_name_mapping)
gt_table_model_5 <- create_gt_table(schoenfeld_results_model_5, "Model 5", var_name_mapping)

# Print the gt tables in the viewer
gt_table_model_1
gt_table_model_2
gt_table_model_3
gt_table_model_4
gt_table_model_5

# Print the Schoenfeld test results in the console
print(schoenfeld_test_results_model_2)
print(schoenfeld_test_results_model_3)
print(schoenfeld_test_results_model_4)
print(schoenfeld_test_results_model_5)
```

```{r Plot the Results of the Schoenfeld Test for Model 5 (All Proposed Covariates)}
# Variable labels for each covariate in Model 5
var_labels <- c("Beta(t) for Depression Level at Year 1",
                "Beta(t) for History of Mental Health Treatment",
                "Beta(t) for History of Psychiatric Hospitalization",
                "Beta(t) for History of Suicide Attempt",
                "Beta(t) for Calendar Year of Injury",
                "Beta(t) for Age at Injury",
                "Beta(t) for Sex",
                "Beta(t) for Educational Attainment at Injury",
                "Beta(t) for Employment Status at Injury",
                "Beta(t) for Marital Status at Injury",
                "Beta(t) for Medicaid Status",
                "Beta(t) for Mechanism of Injury",
                "Beta(t) for Problematic Substance Use at Injury",
                "Beta(t) for Problematic Substance Use at Year 1",
                "Beta(t) for Function Factor Score at Year 1")

# Create and save the Schoenfeld residual plots for Model 5
schoenfeld_residuals_plots <- list()
for (i in 1:length(var_labels)) {
  plot_name <- paste("schoenfeld_residuals_model_5_var_", i, ".png", sep = "")
  plot_path <- here(schoenfeld_residuals_plots_dir, plot_name)
  schoenfeld_residuals_plots[[i]] <- plot_schoenfeld_combined_layout(schoenfeld_test_results_model_5, i, var_labels[i])
  ggsave(plot_path, schoenfeld_residuals_plots[[i]], width = 7, height = 5, dpi = 300)
}

# Define a function to combine and save grouped plots
save_combined_plots <- function(plots, start_index, end_index, ncol, file_name) {
  combined_plot <- do.call(grid.arrange, c(plots[start_index:end_index], ncol = ncol))
  file_path <- here(schoenfeld_residuals_plots_dir, file_name)
  ggsave(file_path, plot = combined_plot, width = 21, height = 5.5)
}

# Combine and save plots in groups
save_combined_plots(schoenfeld_residuals_plots, 1, 3, 3, "combined_schoenfeld_plot_for_model_5_vars_1-3.png")
save_combined_plots(schoenfeld_residuals_plots, 4, 6, 3, "combined_schoenfeld_plot_for_model_5_vars_4-6.png")
save_combined_plots(schoenfeld_residuals_plots, 7, 9, 3, "combined_schoenfeld_plot_for_model_5_vars_7-9.png")
save_combined_plots(schoenfeld_residuals_plots, 10, 12, 3, "combined_schoenfeld_plot_for_model_5_vars_10-12.png")
save_combined_plots(schoenfeld_residuals_plots, 13, 15, 3, "combined_schoenfeld_plot_for_model_5_vars_13-15.png")
```

2.  **Linearity in the Log-Hazard:**

-   **Assessment Using Plots:** You can plot the scaled Schoenfeld residuals against each continuous covariate. If the relationship looks non-linear, this might indicate a violation of the linearity assumption.
-   **Adding Polynomial Terms:** If non-linearity is detected, you can add polynomial terms (like the square or cube of the covariate) to the model to capture this non-linear relationship.

Martingale residuals are a type of residual used in survival analysis, particularly in the context of Cox proportional hazards models. They play a crucial role in diagnostic checking of the model, allowing for the assessment of its fit and the identification of potential inadequacies or areas for improvement. Understanding and assessing Martingale residuals are essential for several reasons.

### Definition of Martingale Residuals

Martingale residuals arise from the Cox proportional hazards model's mathematical formulation, reflecting the difference between the observed number of events and the expected number of events for an individual, given their covariates and the baseline hazard function. Mathematically, for an individual $$ \text i $$, the Martingale residual $M_i$ can be expressed as: $M_i = \delta_i - \Lambda_0(T_i) e^{\beta' X_i}$, where $\delta_i$ is the event indicator (1 if the event has occurred, 0 otherwise), $T_i$ is the observed time, $\Lambda_0(T_i)$ is the cumulative baseline hazard at time $T_i$, $X_i$ is the vector of covariates, and $\beta$ is the vector of coefficients.

#### Importance in Cox Regression Model

1.  **Model Fit Assessment:** Martingale residuals provide insight into how well a Cox regression model fits the data. They can help identify whether the model accurately captures the relationship between the covariates and the survival time. A good fit is indicated by residuals that are symmetrically distributed around zero.

2.  **Identification of Non-Proportional Hazards:** The Cox model assumes proportional hazards--that is, the hazard ratios between groups defined by covariates are constant over time. Plotting Martingale residuals against time or other covariates can help identify violations of this assumption. For example, if residuals display a systematic pattern when plotted against time, this may indicate that the hazard ratios are not constant, suggesting the need for model modifications such as stratification or the introduction of time-dependent covariates.

3.  **Detecting Influential Observations:** Large absolute values of Martingale residuals may indicate observations with a particularly strong influence on the model, such as outliers or individuals whose survival time is not well explained by the model. Investigating these cases can provide insights into data quality or suggest areas where the model could be improved, for instance, by adding interaction terms or nonlinear effects.

4.  **Functional Form of Covariates:** Plotting Martingale residuals against covariates can help in assessing the functional form of the relationship between covariates and the hazard. For instance, a nonlinear relationshp might be indicated by a systematic pattern in the plot, suggesting that transforming the covariate or including polynomial terms could improve the model.

5.  **Assessing Adequacy of Covariates:** Martingale residuals can also be used to assess whether the set of covariates included in the model is adequate. Residuals that show no pattern when plotted against covariates not included in the model suggest that those covariates may not be necessary. Conversely, identifiable patterns may indicate omitted variable bias.

In summary, Martingale residuals are a fundamental diagnostic tool in survival analysis using Cox regression models. They help in assessing the model's fit, identifying violations of model assumptions, detecting influential observations, and guiding model improvements, ultimately ensuring more accurate and reliable results.

------------------------------------------------------------------------

Martingale residuals are a diagnostic tool used in Cox proportional hazards models. They help to assess the adequacy of a fitted model by comparing the observed event times to the expected event times under the model. The primary purpose of Martingale residuals is to identify deviations from the model assumptions, such as non-proportional hazards or incorrect functional form of covariates.

Martingale residuals are calculated based on continuous predictor variables. They measure the difference between the observed event times and the expected event times under the proportional hazards assumption.

In the Cox model, Martingale residuals are calculated as the difference between the observed event indicator (0 or 1) and the predicted event probability at each observed event time for each individual.

**Purpose of Martingale Residuals:** 1. **Model Diagnostics:** Martingale residuals are used to check the goodness-of-fit of the model. Large absolute values of Martingale residuals may indicate cases that are not well explained by the model. 2. **Identify Non-Linearity:** By plotting Martingale residuals against covariates, one can identify non-linear relationships between covariates and the hazard function. 3. **Detect Influential Observations:** Observations with large Martingale residuals may be influential cases or outliers that have a significant impact on the model.

**Expected Results:** - **Zero Mean:** If the model is correctly specified, the Martingale residuals will have an expected mean of zero. - **Interpretation:** A positive Martingale residual suggests that the observed survival time is longer than expected under the model (the individual survived longer than expected), whereas a negative residual indicates the opposite (the individual died earlier than expected). **Limitations:** While useful, Martingale residuals have limitations. They can be difficult to interpret in the presence of censored data, and extreme values may reflect model misspecification or influential observations rather than true deviations.

------------------------------------------------------------------------

### Plotting Martingale Residuals

Plotting Martingale residuals in R requires a Cox proportional hazards model to have been fitted using the `coxph()` function from the `survival` package.

1.  **Calculate Martingale Residuals:** Use the `residuals()` function with the argument `type = "martingale"`.

```{r Calculate Martingale Residuals}
martingale_residuals <- residuals(model_5, type = "martingale")
```

2.  **Plot Martingale Residuals:** Plot the residuals against a covariate or the fitted values to assess the model.

```{r Plot Martingale Residuals}
# # Calculate the adjusted partial residuals for the covariate
# partial_res <- martingale_res + model_5$coefficients[1] * complete_cases_all$covariate

# Create a data frame of continuous covariates and Martingale residuals for plotting
martingale_plot_data <- data.frame(Calendar_Year = complete_cases_all$calendar_year_of_injury,
                                   Age_at_Injury = complete_cases_all$age_at_injury,
                                   Education_Level = complete_cases_all$education_level_at_injury,
                                   Function_Factor_Score = complete_cases_all$func_score_at_year_1,
                                   Martingale_Residuals = martingale_residuals)
```

```{r Plot Figure 19-1}
# Filter out non-finite values from the data
martingale_plot_data <- martingale_plot_data |>
  filter(is.finite(Calendar_Year) & is.finite(Martingale_Residuals))

# Plot Martingale residuals against calendar year at injury
gg.calendar_year_of_injury_vs_martingale <- ggplot(martingale_plot_data, aes(x = Calendar_Year, y = Martingale_Residuals)) +
  geom_point() + # Plot points
  # geom_hline(yintercept = 0, color = "#EF5350", size = 1.25) + # Add a horizontal line at y = 0
  geom_smooth(method = "loess", span = 0.9, color = "#EF5350", size = 1.25) + # Add a Loess curve
  labs(x = "Calendar Year of Injury", y = "Martingale Residuals", title = "Martingale Residuals vs. Calendar Year of Injury") +
  scale_y_continuous(breaks = seq(-3.0, 2.0, by = 1.0), limits = c(-3.0, 2.0)) + # Adjust y-axis tick values
  theme_minimal(base_family = "Proxima Nova") +
  theme(plot.title = element_text(size = 18)) +
  customization_martingale

# Save the plot
ggsave(here(martingale_residuals_plots_dir, "figure_19-1_calendar_year_of_injury_vs_martingale_residuals.png"), 
       plot = gg.calendar_year_of_injury_vs_martingale,
       width = 10, # Specify the width in inches
       height = 6, # Specify the height in inches
       bg = "#FFFFFF",
       dpi = 300)
```

```{r Plot Figure 19-2}
# Filter out non-finite values from the data
martingale_plot_data <- martingale_plot_data |>
  filter(is.finite(Age_at_Injury) & is.finite(Martingale_Residuals))

# Plot Martingale residuals against age at injury
gg.age_at_injury_vs_martingale <- ggplot(martingale_plot_data, aes(x = Age_at_Injury, y = Martingale_Residuals)) +
  geom_point() + # Plot points
  # geom_hline(yintercept = 0, color = "#EF5350", size = 1.25) + # Add a horizontal line at y = 0
  geom_smooth(method = "loess", color = "#EF5350", size = 1.25) + # Add a Loess curve
  labs(x = "Age at Injury", y = "Martingale Residuals", title = "Martingale Residuals vs. Age at Injury") +
  scale_x_continuous(breaks = seq(16, 96, by = 20), limits = c(15, 100)) + # Adjust x-axis tick values and limits
  scale_y_continuous(breaks = seq(-3.0, 2.0, by = 1.0), limits = c(-3.0, 2.0)) + # Adjust y-axis tick values
  theme_minimal(base_family = "Proxima Nova") +
  theme(plot.title = element_text(size = 18)) +
  customization_martingale

# Save the plot
ggsave(here(martingale_residuals_plots_dir, "figure_19-2_age_at_injury_vs_martingale_residuals.png"), 
       plot = gg.age_at_injury_vs_martingale,
       width = 10, # Specify the width in inches
       height = 6, # Specify the height in inches
       bg = "#FFFFFF",
       dpi = 300)
```

```{r Plot Figure 19-3}
# Filter out non-finite values from the data
martingale_plot_data <- martingale_plot_data |>
  filter(is.finite(Education_Level) & is.finite(Martingale_Residuals))

# Plot Martingale residuals against education level at injury
gg.education_level_at_injury_vs_martingale <- ggplot(martingale_plot_data, aes(x = Education_Level, y = Martingale_Residuals)) +
  geom_point() + # Plot points
  # geom_hline(yintercept = 0, color = "#EF5350", size = 1.25) + # Add a horizontal line at y = 0
  geom_smooth(method = "loess", color = "#EF5350", size = 1.25) + # Add a Loess curve
  labs(x = "Education Level at Injury", y = "Martingale Residuals", title = "Martingale Residuals vs. Education Level at Injury") +
  scale_y_continuous(breaks = seq(-3.0, 2.0, by = 1.0), limits = c(-3.0, 2.0)) + # Adjust y-axis tick values
  theme_minimal(base_family = "Proxima Nova") +
  theme(plot.title = element_text(size = 18)) +
  customization_martingale

# Save the plot
ggsave(here(martingale_residuals_plots_dir, "figure_19-3_education_level_at_injury_vs_martingale_residuals.png"), 
       plot = gg.education_level_at_injury_vs_martingale,
       width = 10, # Specify the width in inches
       height = 6, # Specify the height in inches
       bg = "#FFFFFF",
       dpi = 300)
```

```{r Plot 19-4}
# Filter out non-finite values from the data
martingale_plot_data <- martingale_plot_data |>
  filter(is.finite(Function_Factor_Score) & is.finite(Martingale_Residuals))

# Plot Martingale residuals against education level at injury
gg.function_factor_score_at_year_1_vs_martingale <- ggplot(martingale_plot_data, aes(x = Function_Factor_Score, y = Martingale_Residuals)) +
  geom_point() + # Plot points
  # geom_hline(yintercept = 0, color = "#EF5350", size = 1.25) + # Add a horizontal line at y = 0
  geom_smooth(method = "loess", color = "#EF5350", size = 1.25) + # Add a Loess curve
  labs(x = "Function Factor Score at Year 1", y = "Martingale Residuals", title = "Martingale Residuals vs. Function Factor Score at Year 1") +
  scale_y_continuous(breaks = seq(-3.0, 2.0, by = 1.0), limits = c(-3.0, 2.0)) + # Adjust y-axis tick values
  theme_minimal(base_family = "Proxima Nova") +
  theme(plot.title = element_text(size = 18)) +
  customization_martingale

# Save the plot
ggsave(here(martingale_residuals_plots_dir, "figure_19-4_function_factor_score_at_year_1_vs_martingale_residuals.png"), 
       plot = gg.function_factor_score_at_year_1_vs_martingale,
       width = 10, # Specify the width in inches
       height = 6, # Specify the height in inches
       bg = "#FFFFFF",
       dpi = 300)
```

These plots visualize the relationship between the continuous covariates (calendar year, age, education level, and function factor scores, in this case) and the survival outcome, as adjusted by other variables in the model. It can reveal patterns indicating non-linearity, model misspecification, or influential observations. Adjustments or transformations to the model or the covariates might be necessary based on insights from these residuals.

### Statistical Tests with Martingale Residuals

Martingale residuals primarily serve as a diagnostic tool to assess model fit visually rather than through specific statistical tests. They help identify non-linear effects of covariates on the hazard function and potential outliers. Unlike Schoenfeld residuals, which are used to test the proportional hazards assumption (with tests like the Grambsch-Therneau test), Martingale residuals don't have a direct, widely used statistical test associated with them for hypothesis testing.

However, one can use Martingale residuals in a more analytical approach to test for non-linearity or to identify influential observations. For instance, plotting Martingale residuals against each covariate can help in visually detecting non-linear relationships. Additionally, a common practice is to fit a smoothed curve (like a lowess curve) to the plot of Martingale residuals versus covariates to assess if there's a systematic deviation from zero, which would suggest non-linearity.

## Plotting Survival Curves

```{r Create Prediction Data Frames}
# Define the stratum for the Model 1 plot
stratum <- data.frame(depression_level_at_year_1 = levels(complete_cases_all$depression_level_at_year_1))
rownames(stratum) <- letters[1:nrow(stratum)] # Ensure the length of row names matches the number of rows in stratum

# Define the strata for the Model 5 plot
strata <- expand.grid(
  depression_level_at_year_1 = levels(complete_cases_all$depression_level_at_year_1),
  sex = levels(complete_cases_all$sex)
  )
rownames(strata) <- letters[1:nrow(strata)] # Ensure the length of row names matches the number of rows in strata

# Define the average participant
average_participant <- expand.grid(
  depression_level_at_year_1 = levels(complete_cases_all$depression_level_at_year_1),
  sex = levels(complete_cases_all$sex),
  calendar_year_of_injury = median(complete_cases_all$calendar_year_of_injury),
  age_at_injury = median(complete_cases_all$age_at_injury),
  education_level_at_injury = median(complete_cases_all$education_level_at_injury),
  employment_at_injury = "Competitively Employed",
  marital_status_at_injury = "Single",
  rehab_payor_primary_type = "Non-Medicaid",
  cause_of_injury = "Vehicular",
  drs_total_at_year_1 = median(complete_cases_all$drs_total_at_year_1),
  fim_total_at_year_1 = median(complete_cases_all$fim_total_at_year_1),
  gose_total_at_year_1 = median(complete_cases_all$gose_total_at_year_1),
  func_score_at_year_1 = median(complete_cases_all$func_score_at_year_1),
  mental_health_tx_hx = "Denied any history of mental health treatment",
  psych_hosp_hx = "Denied any history of psychiatric hospitalization",
  problematic_substance_use_at_injury = "No",
  problematic_substance_use_at_year_1 = "No",
  suicide_attempt_hx = "Denied any history of suicide attempt"
  )
rownames(average_participant) <- letters[1:nrow(average_participant)]
```

```{r Generate Survival Curves}
# Fit the survival model
cxsf0 <- survfit(model_1, newdata = strata, conf.type = "none")
surv_cxsf0 <- surv_summary(cxsf0, data = complete_cases_all) |>  # Summarize the survival model
  tibble()
m_newdat0 <- average_participant[as.character(surv_cxsf0$strata), ]  # Match new data with survival summary strata

# Fit the survival model
cxsf <- survfit(model_5, newdata = average_participant, conf.type = "none")
surv_cxsf <- surv_summary(cxsf, data = complete_cases_all) |>  # Summarize the survival model
  tibble()
m_newdat <- average_participant[as.character(surv_cxsf$strata), ]  # Match new data with survival summary strata

# Define the crop limit
crop <- 0.5
```

```{r Plot the Survival Curves for Model 1}
# Combine objects for Model 1
surv_model_1 <- cbind(surv_cxsf0, m_newdat0)

# Plot the survival curve of the unadjusted model
gg.surv.model1 <- surv_model_1 |>
  ggsurvplot_df(
    surv.geom = geom_line,
    color = "depression_level_at_year_1",
    xlab = "Time After Initial Interview (years)",
    ylab = "Survival Probability",
    legend.title = "Depression Level at Year 1",
    # legend.labs = c("No Depression", "Minor Depression", "Major Depression"),
    legend = c(0.175, 0.1),
    conf.int = FALSE,
    censor = FALSE,
    surv.scale = "percent",
    break.time.by = 0.5, 
    xlim = c(0, 5), # Limit x-axis to 5 years
    # ylim = c(crop, 1),
    palette = c("#90cbf9", "#2196f3", "#114b7a"),
    ggtheme = theme_classic(),
    ) + 
  customization_survival_curves

ggsave(here(survival_curves_plots_dir, "figure_19-1_kaplan_meier_curves_model_1_5_year_followup.png"),
       gg.surv.model1, dpi = 300)
```

```{r Plot the Survival Curves for Model 5}
# Combine objects for Model 5
surv_model_5 <- cbind(surv_cxsf, m_newdat)

# Plot the survival curve of Model 5
gg.surv.model5 <- surv_model_5 |>
  ggsurvplot_df(
    surv.geom = geom_line,
    color = "depression_level_at_year_1",
    linetype = "sex",
    #title = "Effect of Depression Level at Year 1 on Survival",
    xlab = "Time After Initial Interview (years)",
    ylab = "Survival Probability",
    legend = c(0.175, 0.175),
    conf.int = FALSE,
    censor = FALSE,
    surv.scale = "percent",
    break.time.by = 1,
    xlim = c(0, 5), # Limit x-axis to 5 years
    ylim = c(crop, 1),
    palette = c("#90cbf9", "#2196f3", "#114b7a"),
    risk.table = TRUE,  # Add this line to display the risk set size
    # risk.table.height = 0.25,  # Adjust the height of the risk table
    ggtheme = theme_classic(),
  ) +
  labs(linetype = "Sex", color = "Depression Level at Year 1") +
  customization_survival_curves

ggsave(here(survival_curves_plots_dir, "figure_19-2_kaplan_meier_curves_model_5_5_year_followup.png"),
       gg.surv.model5, dpi = 300)
```

```{r Plot the Survival Curves with Risk Set, include = FALSE}
# Fit the Kaplan-Meier survival curve based on the Cox model
surv_fit <- survfit(model_5)

# Plot the Kaplan-Meier curve with ggplot2
ggsurvplot(surv_fit, data = complete_cases_all, 
           risk.table = TRUE, # Add risk table
           conf.int = TRUE, # Add confidence interval
           pval = TRUE, # Add p-value
           ggtheme = theme_classic(), # Use minimal theme for plot
           palette = "Dark2") # Use Dark2 color palette
```


```{r Create Forest Plot of Model 5 Results (Approach 1: forestplot)}
# Extract model summary
model_summary <- summary(model_5)

# Extract coefficients, confidence intervals, and p-values
coef <- model_summary$coefficients
confint <- model_summary$conf.int

# Create a table for the forest plot
forest_plot_table <- data.frame(
  Variable = rownames(coef),
  HR = coef[, "exp(coef)"],
  Lower_CI = confint[, "lower .95"],
  Upper_CI = confint[, "upper .95"],
  P_value = coef[, "Pr(>|z|)"]
)

# Replace the variable names with the display names
forest_plot_table$Variable <- forest_plot_var_name_mapping[forest_plot_table$Variable]

# Handle any variables that may not have a mapping defined
forest_plot_table$Variable[is.na(forest_plot_table$Variable)] <- rownames(coef)[is.na(forest_plot_var_name_mapping[rownames(coef)])]

# Format the table for the forest plot
forest_plot_table_text <- cbind(
  Variable = forest_plot_table$Variable,
  HR = sprintf("%.2f", forest_plot_table$HR),
  CI = paste0("(", sprintf("%.2f", forest_plot_table$Lower_CI), " — ", sprintf("%.2f", forest_plot_table$Upper_CI), ")"),
  P_value = sprintf("%.3f", forest_plot_table$P_value)
)

# Add a title row
forest_plot_table_text <- rbind(
  c("Variable", "HR", "95% CI", "p-value"),
  forest_plot_table_text
)

# Create the forest plot
forestplot(
  labeltext = forest_plot_table_text,
  mean = c(NA, forest_plot_table$HR),  # Add NA for the header row
  lower = c(NA, forest_plot_table$Lower_CI),
  upper = c(NA, forest_plot_table$Upper_CI),
  is.summary = c(TRUE, rep(FALSE, nrow(forest_plot_table))),
  xlab = "Hazard Ratio",
  title = "Forest Plot of Cox Proportional Hazards Model 5"
)
```

```{r Create Forest Plot of Model 5 Results (Approach 2: ggplot2)}
# Extract model summary in tidy format
model_5_tidy <- tidy(model_5, exponentiate = TRUE, conf.int = TRUE) %>%
  mutate(
    term = plyr::revalue(as.character(term), forest_plot_var_name_mapping), 
    term = factor(term, levels = forest_plot_var_name_mapping),
    estimate = round(estimate, 2),
    conf.low = round(conf.low, 2),
    conf.high = round(conf.high, 2),
    conf.int = paste0(conf.low, "-", conf.high),
    p.value = ifelse(p.value < 0.001, "< 0.001", round(p.value, 3))
  )

# Reverse factor levels of 'term' to display mental health covariates first
model_5_tidy$term <- factor(model_5_tidy$term, levels = rev(levels(model_5_tidy$term)))

# Create Plot Components
# Point & Line Range (Hazard Ratio & CI)
point_line_range <- ggplot(model_5_tidy, aes(x = estimate, y = term)) +
  geom_point() +
  geom_errorbarh(aes(xmin = conf.low, xmax = conf.high), height = 0) +
  geom_vline(xintercept = 1, linetype = "dashed") +
  annotate("text", x = 0.5, y = Inf, label = "Protective Factor", hjust = 1, vjust = 1, family = "Proxima Nova", fontface = "bold", size = 3.5) +
  annotate("text", x = 1.5, y = Inf, label = "Risk Factor", hjust = 0, vjust = 1, family = "Proxima Nova", fontface = "bold", size = 3.5) +
  labs(x = "Hazard Ratio (95% CI)", y = "") +
  theme_classic() + 
  customization +
  scale_x_continuous(
    breaks = seq(
      -1, # Start the x-axis at -1
      ceiling(max(model_5_tidy$conf.high)), 
      by = 1
    ),
    limits = c(-1, ceiling(max(model_5_tidy$conf.high))) # Ensure the entire x-axis is displayed
  ) 

# Estimate Annotations (HR and CI numbers)
estimate_annotations <- ggplot(model_5_tidy, aes(x = 2.5, y = term, label = paste0(estimate, " (", conf.int, ")"))) +
  geom_text(hjust = 0, size = 3, family = "Proxima Nova") +
  annotate("text", x = 2.5, y = Inf, label = "Hazard Ratio (95% CI)", hjust = 0, vjust = 1, family = "Proxima Nova", fontface = "bold", size = 3.5) +
  theme_void()

# P-Value Annotations
p_value_annotations <- ggplot(model_5_tidy, aes(x = 0, y = term)) +
  geom_text(aes(label = p.value), hjust = 1, size = 3, family = "Proxima Nova", 
            fontface = ifelse(model_5_tidy$p.value < 0.05, "bold", "plain")) +  # Conditional bolding
  annotate("text", x = 0, y = Inf, label = "p-value", hjust = 1, vjust = 1, family = "Proxima Nova", fontface = "bold", size = 3.5) +
  theme_void()

# Combine Plots
combined_plot <- point_line_range + estimate_annotations + p_value_annotations +
  plot_layout(widths = c(2, 1, 1))

# Display Plot
print(combined_plot)
```

3.  **Multicollinearity:**

There should be no perfect linear relationships among the independent variables. This means that one independent variable should not be a perfect predictor of another. Multicollinearity can be assessed using techniques like variance inflation factor (VIF).
